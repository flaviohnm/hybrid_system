{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ae555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 1: IMPORTAÇÕES E SETUP GERAL\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbc5229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "# --- Nossas funções auxiliares agora são importadas! ---\n",
    "from helper.utils import (\n",
    "    definir_seed,\n",
    "    carregar_serie,\n",
    "    dividir_serie_temporal,\n",
    "    preparar_dados_para_neuralforecast\n",
    ")\n",
    "\n",
    "# --- Importações específicas para o treinamento ---\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pmdarima as pm\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS, MLP, LSTM, Autoformer, NHITS\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c6ad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 2: PIPELINE DE EXPERIMENTO\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f152a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_melhor_arima_auto(treino_log, freq):\n",
    "    # (Mantenha sua função original aqui)\n",
    "    print(\"Buscando melhor ordem ARIMA com auto_arima...\")\n",
    "    m = 12 if freq.startswith('M') else (4 if freq.startswith('Q') else 1)\n",
    "    auto_arima_model = pm.auto_arima(treino_log, m=m, seasonal=True, trace=False,\n",
    "                                     error_action='ignore', suppress_warnings=True, stepwise=True)\n",
    "    print(\n",
    "        f\"Melhor ordem encontrada: {auto_arima_model.order} Sazonal: {auto_arima_model.seasonal_order}\")\n",
    "    return auto_arima_model.order, auto_arima_model.seasonal_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e125c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executar_experimento(nome_da_serie, horizonte):\n",
    "    try:\n",
    "        # --- Configurações Iniciais ---\n",
    "        SEED = 42\n",
    "        definir_seed(SEED)\n",
    "        MAX_INPUT_SIZE = 24\n",
    "        MAX_STEPS_NEURAL = 150\n",
    "\n",
    "        # --- Carga e Preparação dos Dados ---\n",
    "        serie_original = carregar_serie(nome_da_serie)\n",
    "        percentual_treino = 1 - (horizonte / len(serie_original))\n",
    "        if percentual_treino < 0.5:\n",
    "            print(\n",
    "                f\"AVISO: Horizonte {horizonte} é muito grande para '{nome_da_serie}'. Pulando.\")\n",
    "            return None\n",
    "\n",
    "        treino_orig, teste_orig = dividir_serie_temporal(\n",
    "            serie_original, percentual_treino=percentual_treino)\n",
    "        serie_log = np.log(serie_original)\n",
    "        treino_log, _ = dividir_serie_temporal(\n",
    "            serie_log, percentual_treino=percentual_treino)\n",
    "        freq = serie_original.index.freqstr or pd.infer_freq(\n",
    "            serie_original.index)\n",
    "        if freq is None:\n",
    "            return None\n",
    "\n",
    "        previsoes_teste = {'y_true': teste_orig.values}\n",
    "\n",
    "        # --- 1. Modelo ARIMA (Base para ambos os híbridos) ---\n",
    "        modelo_arima = None\n",
    "        try:\n",
    "            print(f\"Processando: ARIMA para '{nome_da_serie}'\")\n",
    "            ordem, ordem_sazonal = encontrar_melhor_arima_auto(\n",
    "                treino_log, freq)\n",
    "            modelo_arima = ARIMA(treino_log.asfreq(\n",
    "                freq), order=ordem, seasonal_order=ordem_sazonal).fit()\n",
    "            preds_log_teste_arima = modelo_arima.forecast(steps=horizonte)\n",
    "            previsoes_teste['ARIMA'] = np.exp(preds_log_teste_arima).values\n",
    "        except Exception as e:\n",
    "            print(f\"AVISO: ARIMA falhou para '{nome_da_serie}': {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "        # --- 2. Modelos Neurais Puros ---\n",
    "\n",
    "        df_treino_log_nf = preparar_dados_para_neuralforecast(\n",
    "            treino_log, nome_da_serie)\n",
    "\n",
    "        modelos_para_testar = {'N-BEATS': NBEATS, 'MLP': MLP,\n",
    "                               'LSTM': LSTM, 'Autoformer': Autoformer, 'N-HiTS': NHITS}\n",
    "\n",
    "\n",
    "        for nome_modelo, classe_modelo in modelos_para_testar.items():\n",
    "\n",
    "            try:\n",
    "                print(f\"Processando: {nome_modelo}\")\n",
    "                modelo_neural = [classe_modelo(input_size=min(\n",
    "                    2 * horizonte, MAX_INPUT_SIZE), h=horizonte, max_steps=MAX_STEPS_NEURAL, scaler_type='standard', random_seed=SEED)]\n",
    "                nf = NeuralForecast(models=modelo_neural, freq=freq)\n",
    "                nf.fit(df=df_treino_log_nf, verbose=False)\n",
    "                previsoes_teste[nome_modelo] = np.exp(\n",
    "                    nf.predict()[classe_modelo.__name__].values)\n",
    "            except Exception as e:\n",
    "                print(f\"AVISO: {nome_modelo} falhou: {e}\")\n",
    "\n",
    "\n",
    "        # Obter os resíduos do treino para os modelos híbridos\n",
    "\n",
    "        residuos_treino_log = modelo_arima.resid\n",
    "\n",
    "        # --- 3. Modelo Híbrido (MIMO) - Sua implementação original ---\n",
    "\n",
    "        try:\n",
    "            print(\"Processando: Híbrido (MIMO)\")\n",
    "            df_residuos_nf = preparar_dados_para_neuralforecast(\n",
    "                residuos_treino_log, \"residuos\")\n",
    "\n",
    "            # Treina um único modelo para prever todos os H passos\n",
    "            modelo_residuos_mimo = [NBEATS(input_size=min(\n",
    "                2*horizonte, MAX_INPUT_SIZE), h=horizonte, max_steps=MAX_STEPS_NEURAL, scaler_type='standard', random_seed=SEED)]\n",
    "\n",
    "            nf_residuos_mimo = NeuralForecast(\n",
    "                models=modelo_residuos_mimo, freq=freq)\n",
    "\n",
    "            nf_residuos_mimo.fit(df=df_residuos_nf, verbose=False)\n",
    "\n",
    "            preds_residuos_log_mimo = nf_residuos_mimo.predict()[\n",
    "                'NBEATS'].values\n",
    "            previsoes_teste['Híbrido (MIMO)'] = previsoes_teste['ARIMA'] + \\\n",
    "                preds_residuos_log_mimo\n",
    "        except Exception as e:\n",
    "            print(f\"AVISO: Híbrido (MIMO) falhou: {e}\")\n",
    "\n",
    "        # =========================================================================================\n",
    "        # --- 4. Híbrido (Recursive-Direct) - IMPLEMENTAÇÃO FINAL ROBUSTA ---\n",
    "        # =========================================================================================\n",
    "        try:\n",
    "            print(\"Processando: Híbrido (Recursive-Direct)\")\n",
    "\n",
    "            # --- 4.1 Preparação dos dados em formato Painel ---\n",
    "            lista_dfs_horizontes = []\n",
    "            input_size_nbeats = min(2 * horizonte, MAX_INPUT_SIZE)\n",
    "\n",
    "            for h_step in range(1, horizonte + 1):\n",
    "                # Cria um df para o horizonte específico\n",
    "                df_residuos_h = residuos_treino_log.to_frame(name='y')\n",
    "                df_residuos_h['ds'] = df_residuos_h.index\n",
    "                df_residuos_h['y'] = df_residuos_h['y'].shift(-h_step + 1)\n",
    "\n",
    "                # O ID único agora é o próprio horizonte\n",
    "                df_residuos_h['unique_id'] = f'h_{h_step}'\n",
    "\n",
    "                df_residuos_h.dropna(inplace=True)\n",
    "\n",
    "                # Só adiciona o df se ele tiver dados suficientes\n",
    "                if len(df_residuos_h) >= input_size_nbeats + 1:\n",
    "                    lista_dfs_horizontes.append(df_residuos_h)\n",
    "\n",
    "            if not lista_dfs_horizontes:\n",
    "                raise ValueError(\n",
    "                    \"Nenhum horizonte tinha dados suficientes para treinar o modelo de resíduos.\")\n",
    "\n",
    "            # Concatena todos os dataframes em um só (formato painel)\n",
    "            df_treino_residuos_painel = pd.concat(lista_dfs_horizontes)\n",
    "\n",
    "            # --- 4.2 Treinamento e Previsão ---\n",
    "            # Treina um único modelo N-BEATS que aprenderá com todos os horizontes (unique_ids)\n",
    "            modelo_residuos_direct = [NBEATS(\n",
    "                input_size=input_size_nbeats, h=1, max_steps=MAX_STEPS_NEURAL, scaler_type='standard', random_seed=SEED)]\n",
    "            nf_residuos_direct = NeuralForecast(\n",
    "                models=modelo_residuos_direct, freq=freq)\n",
    "\n",
    "            # O fit é feito uma única vez no dataframe de painel\n",
    "            nf_residuos_direct.fit(df=df_treino_residuos_painel, verbose=False)\n",
    "\n",
    "            # O predict irá gerar uma previsão para cada unique_id (cada horizonte)\n",
    "            preds_df = nf_residuos_direct.predict()\n",
    "\n",
    "            # Ordena as previsões pela ordem do horizonte para garantir a sequência correta\n",
    "            preds_df['h_step'] = preds_df['unique_id'].str.replace(\n",
    "                'h_', '').astype(int)\n",
    "            preds_df.sort_values(by='h_step', inplace=True)\n",
    "\n",
    "            preds_residuos_log_direct = preds_df['NBEATS'].values\n",
    "\n",
    "            # Garantir que o array de predições tenha o tamanho do horizonte, preenchendo com 0 se algum especialista não foi treinado\n",
    "            if len(preds_residuos_log_direct) < horizonte:\n",
    "                preds_completas = np.zeros(horizonte)\n",
    "                # h_1 está no índice 0\n",
    "                indices_validos = preds_df['h_step'].values - 1\n",
    "                preds_completas[indices_validos] = preds_residuos_log_direct\n",
    "                preds_residuos_log_direct = preds_completas\n",
    "\n",
    "            # --- 4.3 Combinação Final ---\n",
    "            previsoes_teste['Híbrido (Recursive-Direct)'] = previsoes_teste['ARIMA'] + \\\n",
    "                preds_residuos_log_direct\n",
    "\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            print(f\"AVISO: Híbrido (Recursive-Direct) falhou: {e}\")\n",
    "            traceback.print_exc()\n",
    "            # Garante que a coluna exista com NaNs para não quebrar a estrutura final\n",
    "            previsoes_teste['Híbrido (Recursive-Direct)'] = np.nan\n",
    "\n",
    "        # --- Finalização ---\n",
    "        df_final = pd.DataFrame(previsoes_teste, index=teste_orig.index)\n",
    "        df_final['dataset'] = nome_da_serie\n",
    "        df_final['horizonte'] = horizonte\n",
    "        return df_final.reset_index().rename(columns={'index': 'ds'})\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(\n",
    "            f\"ERRO GERAL no processamento de '{nome_da_serie}' para o horizonte {horizonte}: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee37e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 3: ORQUESTRADOR (LÓGICA DA CAMADA SILVER)\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a2d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configurações ---\n",
    "LISTA_DE_DATASETS = ['AirPassengers', 'co2', 'nottem', 'austres', 'lynx']\n",
    "VETOR_DE_HORIZONTES = [10, 12, 15, 24]\n",
    "output_dir = \"./data/silver\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, \"resultados_completos.csv\")\n",
    "\n",
    "# --- Lógica de Execução Incremental ---\n",
    "# Apaga o arquivo antigo para garantir uma execução limpa\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "header_escrito = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e2384",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in tqdm(LISTA_DE_DATASETS, desc=\"Processando Datasets\"):\n",
    "    for horizonte in tqdm(VETOR_DE_HORIZONTES, desc=f\"Testando Horizontes para {dataset}\", leave=False):\n",
    "        # Executa o experimento para uma combinação de dataset e horizonte\n",
    "        df_resultado_detalhado = executar_experimento(dataset, horizonte)\n",
    "\n",
    "        if df_resultado_detalhado is not None:\n",
    "            # Lógica para salvar incrementalmente no arquivo da camada Silver\n",
    "            if not header_escrito:\n",
    "                # Escreve o cabeçalho apenas na primeira vez\n",
    "                df_resultado_detalhado.to_csv(\n",
    "                    output_file, index=False, mode='w', header=True)\n",
    "                header_escrito = True\n",
    "            else:\n",
    "                # Anexa os novos resultados sem o cabeçalho\n",
    "                df_resultado_detalhado.to_csv(\n",
    "                    output_file, index=False, mode='a', header=False)\n",
    "\n",
    "print(f\"\\nProcesso finalizado. Resultados salvos em '{output_file}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybrid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
