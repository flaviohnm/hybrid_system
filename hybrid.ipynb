{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c96030f3be3e4a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T00:52:59.360703Z",
     "start_time": "2025-06-19T00:52:59.356446Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 1: IMPORTAÇÕES E SETUP GERAL\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9716172789275c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T00:52:59.414429Z",
     "start_time": "2025-06-19T00:52:59.376419Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "# Libs de Modelagem e Estatística\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.datasets import get_rdataset\n",
    "from dieboldmariano import dm_test\n",
    "import pmdarima as pm\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS, MLP, LSTM, Autoformer, NHITS\n",
    "\n",
    "# Libs de Avaliação\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7acde5f0e5c4b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 2: FUNÇÕES AUXILIARES (SETUP E PROCESSAMENTO)\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff04ae19676ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def definir_seed(seed_value=42):\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68444ac84157ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_dataset(serie, dataset_name):\n",
    "    dir_path = \"./data/bronze\"\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    file_path = os.path.join(dir_path, f\"{dataset_name.lower()}.csv\")\n",
    "    df = pd.DataFrame({\"date\": serie.index, \"value\": serie.values})\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"-> Cópia do dataset '{dataset_name}' salva em: {file_path}\")\n",
    "\n",
    "def carregar_serie(nome):\n",
    "    print(f\"Buscando dados de '{nome}' via statsmodels...\")\n",
    "    nome_base = nome.lower()\n",
    "\n",
    "    if nome_base == \"airpassengers\":\n",
    "        df = get_rdataset(\"AirPassengers\", package=\"datasets\").data\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1949-01-01\", periods=len(df), freq=\"MS\"),\n",
    "                          name=\"AirPassengers\")\n",
    "    elif nome_base == \"lynx\":\n",
    "        df = get_rdataset(\"lynx\", package=\"datasets\").data\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1821\", periods=len(df), freq=\"A\"), name=\"Lynx\")\n",
    "    elif nome_base == \"co2\":\n",
    "        df = get_rdataset(\"CO2\", package=\"datasets\").data\n",
    "        df = df.ffill()\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1958-03-29\", periods=len(df), freq=\"MS\"),\n",
    "                          name=\"CO2\")\n",
    "    elif nome_base == \"sunspots\":\n",
    "        df = get_rdataset(\"sunspots\", package=\"datasets\").data\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1749-01-01\", periods=len(df), freq=\"MS\"),\n",
    "                          name=\"Sunspots\")\n",
    "    elif nome_base == \"austres\":\n",
    "        df = get_rdataset(\"austres\", package=\"datasets\").data\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1971-03-01\", periods=len(df), freq=\"QS-MAR\"),\n",
    "                          name=\"AustralianResidents\")\n",
    "    elif nome_base == \"nottem\":\n",
    "        df = get_rdataset(\"nottem\", package=\"datasets\").data\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1920-01-01\", periods=len(df), freq=\"MS\"),\n",
    "                          name=\"Nottingham\")\n",
    "    else:\n",
    "        raise ValueError(f\"Lógica de download para a série '{nome}' não implementada.\")\n",
    "\n",
    "    salvar_dataset(serie, nome)\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a220cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_serie_temporal(serie, percentual_treino=0.85):\n",
    "    tamanho_total = len(serie)\n",
    "    ponto_corte_treino = int(tamanho_total * percentual_treino)\n",
    "    treino = serie.iloc[:ponto_corte_treino]\n",
    "    teste = serie.iloc[ponto_corte_treino:]\n",
    "    return treino, teste\n",
    "\n",
    "def preparar_dados_para_neuralforecast(serie, nome_serie):\n",
    "    df = serie.reset_index()\n",
    "    df.columns = ['ds', 'y']\n",
    "    df['unique_id'] = nome_serie\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "767138d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 3: FUNÇÕES PARA CÁLCULO DE MÉTRICAS E MODELAGEM\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c38b31116385f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas(y_true, y_pred, y_train):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100 if np.all(y_true != 0) else np.inf\n",
    "    n = len(y_train)\n",
    "    d = np.sum(np.abs(y_train[1:] - y_train[:-1])) / (n - 1) if n > 1 else np.nan\n",
    "    mase = np.mean(np.abs(y_true - y_pred)) / d if d is not np.nan and d > 0 else np.inf\n",
    "    return {'RMSE': rmse, 'MAPE(%)': mape, 'MASE': mase}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cae6b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 4: PIPELINE AVANÇADO PARA O ARIMA\n",
    "# =========================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcc9d2b54e19eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_melhor_arima_auto(treino_log, freq):\n",
    "    \"\"\"Usa auto_arima para encontrar a melhor ordem ARIMA, incluindo sazonalidade.\"\"\"\n",
    "    print(\"Buscando melhor ordem ARIMA com auto_arima...\")\n",
    "    m = 12 if freq.startswith('M') else (4 if freq.startswith('Q') else 1)\n",
    "    auto_arima_model = pm.auto_arima(treino_log, m=m, seasonal=True, trace=False, error_action='ignore', suppress_warnings=True, stepwise=True)\n",
    "    print(f\"Melhor ordem encontrada: {auto_arima_model.order} Sazonal: {auto_arima_model.seasonal_order}\")\n",
    "    return auto_arima_model.order, auto_arima_model.seasonal_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "189a54af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 5: PIPELINE DE EXPERIMENTO COMPLETO E AVANÇADO\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f7c9b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executar_experimento(nome_da_serie, horizonte):\n",
    "    \"\"\"Executa o pipeline completo com as correções de estabilidade.\"\"\"\n",
    "    try:\n",
    "        SEED = 42; definir_seed(SEED)\n",
    "        MAX_INPUT_SIZE = 24; MAX_STEPS_NEURAL = 150\n",
    "        \n",
    "        serie_original = carregar_serie(nome_da_serie)\n",
    "        \n",
    "        percentual_treino = 1 - (horizonte / len(serie_original))\n",
    "        if percentual_treino < 0.5: # Garante pelo menos 50% de dados para treino\n",
    "             print(f\"AVISO: Horizonte {horizonte} é muito grande para a série '{nome_da_serie}'. Pulando.\")\n",
    "             return None\n",
    "        \n",
    "        treino_orig, teste_orig = dividir_serie_temporal(serie_original, percentual_treino=percentual_treino)\n",
    "        serie_log = np.log(serie_original)\n",
    "        treino_log, _ = dividir_serie_temporal(serie_log, percentual_treino=percentual_treino)\n",
    "        \n",
    "        freq = serie_original.index.freqstr or pd.infer_freq(serie_original.index)\n",
    "        if freq is None: return None\n",
    "\n",
    "        previsoes_teste = {'y_true': teste_orig.values}\n",
    "        \n",
    "        # --- 1. Modelo ARIMA ---\n",
    "        modelo_arima = None\n",
    "        try:\n",
    "            print(\"Processando: ARIMA\")\n",
    "            ordem, ordem_sazonal = encontrar_melhor_arima_auto(treino_log, freq)\n",
    "            modelo_arima = ARIMA(treino_log.asfreq(freq), order=ordem, seasonal_order=ordem_sazonal).fit()\n",
    "            # CORREÇÃO: Usando .forecast() para previsão out-of-sample\n",
    "            preds_log_teste_arima = modelo_arima.forecast(steps=horizonte)\n",
    "            previsoes_teste['ARIMA'] = np.exp(preds_log_teste_arima).values\n",
    "        except Exception as e: print(f\"AVISO: ARIMA falhou: {e}\")\n",
    "\n",
    "        # --- 2. Modelos Neurais Puros ---\n",
    "        df_treino_log_nf = preparar_dados_para_neuralforecast(treino_log, nome_da_serie)\n",
    "        modelos_para_testar = {'N-BEATS': NBEATS, 'MLP': MLP, 'LSTM': LSTM, 'Autoformer': Autoformer, 'NHITS': NHITS}\n",
    "        \n",
    "        for nome_modelo, classe_modelo in modelos_para_testar.items():\n",
    "            try:\n",
    "                print(f\"Processando: {nome_modelo}\")\n",
    "                # CORREÇÃO: Removida a configuração de arquitetura customizada para N-BEATS/NHITS\n",
    "                modelo_neural = [classe_modelo(input_size=min(2 * horizonte, MAX_INPUT_SIZE), h=horizonte, max_steps=MAX_STEPS_NEURAL, scaler_type='standard', random_seed=SEED)]\n",
    "                nf = NeuralForecast(models=modelo_neural, freq=freq)\n",
    "                nf.fit(df=df_treino_log_nf, verbose=False)\n",
    "                previsoes_teste[nome_modelo] = np.exp(nf.predict()[classe_modelo.__name__].values)\n",
    "            except Exception as e: print(f\"AVISO: {nome_modelo} falhou: {e}\")\n",
    "        \n",
    "        # --- 3. Modelo Híbrido (MIMO) ---\n",
    "        if 'ARIMA' in previsoes_teste and modelo_arima is not None:\n",
    "            try:\n",
    "                print(\"Processando: Híbrido (MIMO)\")\n",
    "                residuos_treino_log = modelo_arima.resid\n",
    "                df_residuos_nf = preparar_dados_para_neuralforecast(residuos_treino_log, \"residuos\")\n",
    "                modelo_residuos = [NBEATS(input_size=min(2*horizonte, MAX_INPUT_SIZE), h=horizonte, max_steps=MAX_STEPS_NEURAL, scaler_type='standard', random_seed=SEED)]\n",
    "                nf_residuos = NeuralForecast(models=modelo_residuos, freq=freq)\n",
    "                nf_residuos.fit(df=df_residuos_nf, verbose=False)\n",
    "                preds_residuos_log = nf_residuos.predict()['NBEATS'].values\n",
    "                previsoes_teste['Híbrido (MIMO)'] = previsoes_teste['ARIMA'] + preds_residuos_log\n",
    "            except Exception as e: print(f\"AVISO: Híbrido (MIMO) falhou: {e}\")\n",
    "            \n",
    "        df_final = pd.DataFrame(previsoes_teste, index=teste_orig.index)\n",
    "        df_final['dataset'] = nome_da_serie\n",
    "        df_final['horizonte'] = horizonte\n",
    "        return df_final.reset_index().rename(columns={'index': 'ds'})\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO GERAL no processamento de '{nome_da_serie}' para o horizonte {horizonte}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a005504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 6: ORQUESTRADOR\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df8e17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Datasets:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando dados de 'AirPassengers' via statsmodels...\n",
      "-> Cópia do dataset 'AirPassengers' salva em: ./data/bronze\\airpassengers.csv\n",
      "Processando: ARIMA\n",
      "Buscando melhor ordem ARIMA com auto_arima...\n"
     ]
    }
   ],
   "source": [
    "LISTA_DE_DATASETS = ['AirPassengers', 'co2'] \n",
    "VETOR_DE_HORIZONTES = [12, 24]\n",
    "resultados_gerais = []\n",
    "output_dir = \"./data/silver\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, \"resultados_completos.csv\")\n",
    "\n",
    "for dataset in tqdm(LISTA_DE_DATASETS, desc=\"Processando Datasets\"):\n",
    "    for horizonte in tqdm(VETOR_DE_HORIZONTES, desc=f\"Testando Horizontes para {dataset}\", leave=False):\n",
    "        df_resultado_detalhado = executar_experimento(dataset, horizonte)\n",
    "        if df_resultado_detalhado is not None:\n",
    "            resultados_gerais.append(df_resultado_detalhado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c51cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if resultados_gerais:\n",
    "    df_final = pd.concat(resultados_gerais)\n",
    "    df_final.to_csv(output_file, index=False)\n",
    "    print(f\"\\nArquivo '{output_file}' salvo com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e21be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 7: GERAÇÃO DE RELATÓRIOS A PARTIR DOS ARQUIVOS SALVOS\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a1d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"     GERANDO SUÍTE COMPLETA DE RELATÓRIOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    output_file = os.path.join(output_dir, \"resultados_completos.csv\")\n",
    "    df_results = pd.read_csv(output_file)\n",
    "    \n",
    "    # Extrai os nomes dos modelos das colunas do DataFrame salvo\n",
    "    modelos = [col for col in df_results.columns if col not in ['ds', 'y_true', 'dataset', 'horizonte']]\n",
    "    \n",
    "    # --- 1. Cálculo das Métricas a partir dos resultados brutos ---\n",
    "    y_train_dict = {}\n",
    "    for dataset_nome in df_results['dataset'].unique():\n",
    "        treino, _, _ = dividir_serie_temporal(carregar_serie(dataset_nome))\n",
    "        y_train_dict[dataset_nome] = treino.values\n",
    "\n",
    "    # Transforma o DataFrame de formato 'largo' para 'longo' para facilitar o groupby\n",
    "    df_melted = df_results.melt(id_vars=['ds', 'y_true', 'dataset', 'horizonte'], value_vars=modelos, var_name='Modelo', value_name='y_pred')\n",
    "    \n",
    "    metricas_gerais = []\n",
    "    for (dataset, horizonte, modelo), group in df_melted.groupby(['dataset', 'horizonte', 'Modelo']):\n",
    "        if not group['y_pred'].isnull().all():\n",
    "            metricas = calcular_metricas(group['y_true'], group['y_pred'], y_train_dict[dataset])\n",
    "            metricas['dataset'], metricas['horizonte'], metricas['Modelo'] = dataset, horizonte, modelo\n",
    "            metricas_gerais.append(metricas)\n",
    "    \n",
    "    df_metricas_final = pd.DataFrame(metricas_gerais)\n",
    "    rename_dict = {'RMSE': 'Mean RMSE', 'MAPE(%)': 'Mean MAPE(%)', 'MASE': 'Mean MASE'}\n",
    "    df_metricas_final.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "    # --- Relatório 1: Evolução do Erro por Horizonte ---\n",
    "    print(\"\\n--- RELATÓRIO 1: EVOLUÇÃO DO ERRO (RMSE) POR HORIZONTE ---\")\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.lineplot(data=df_metricas_final, x='horizonte', y='Mean RMSE', hue='Modelo', style='Modelo', markers=True, dashes=False)\n",
    "    plt.title(\"Evolução do Erro (RMSE) com o Aumento do Horizonte\", fontsize=16)\n",
    "    plt.xlabel(\"Horizonte de Previsão\"); plt.ylabel(\"RMSE Médio\"); plt.grid(True)\n",
    "    if not df_metricas_final.empty: plt.xticks(df_metricas_final['horizonte'].unique())\n",
    "    plt.legend(title='Modelo'); plt.show()\n",
    "    \n",
    "    # --- Preparação para os relatórios focados no maior horizonte ---\n",
    "    maior_horizonte = df_metricas_final['horizonte'].max()\n",
    "    df_foco_maior_h = df_metricas_final[df_metricas_final['horizonte'] == maior_horizonte]\n",
    "    display(Markdown(f\"### Análises Detalhadas para o Horizonte Mais Longo ({int(maior_horizonte)} passos)\"))\n",
    "\n",
    "    # --- Relatório 2: Desempenho Geral Agregado (foco no maior horizonte) ---\n",
    "    print(\"\\n--- RELATÓRIO 2: DESEMPENHO GERAL (MÉDIA NO HORIZONTE MAIS LONGO) ---\")\n",
    "    df_agrupado = df_foco_maior_h.groupby('Modelo')[['Mean RMSE', 'Mean MAPE(%)', 'Mean MASE']].mean()\n",
    "    display(df_agrupado.style.format('{:.3f}').highlight_min(axis=0, props='background-color: #4285F4; color: white;'))\n",
    "\n",
    "    # --- Relatório 3: Desempenho Detalhado por Dataset (foco no maior horizonte) ---\n",
    "    print(\"\\n--- RELATÓRIO 3: DESEMPENHO DETALHADO POR DATASET (HORIZONTE MAIS LONGO) ---\")\n",
    "    df_reporte_detalhado = df_foco_maior_h.set_index(['dataset', 'Modelo']).drop(columns=['horizonte'])\n",
    "    display(df_reporte_detalhado.style.format('{:.3f}'))\n",
    "\n",
    "    # --- Relatório 4: Tabela de Ranking dos Modelos (foco no maior horizonte) ---\n",
    "    print(\"\\n--- RELATÓRIO 4: RANKING DOS MODELOS (BASEADO EM RMSE, HORIZONTE MAIS LONGO) ---\")\n",
    "    df_foco_maior_h['Rank'] = df_foco_maior_h.groupby('dataset')['Mean RMSE'].rank().astype(int)\n",
    "    df_pivot_rank = df_foco_maior_h.pivot_table(index='dataset', columns='Modelo', values='Rank')\n",
    "    if len(df_pivot_rank) > 1: df_pivot_rank.loc['Média do Rank'] = df_pivot_rank.mean(axis=0)\n",
    "    display(df_pivot_rank.style.format('{:.1f}').highlight_min(axis=1, props='background-color: #4285F4; color: white;'))\n",
    "    \n",
    "    # --- RELATÓRIO 5: TESTE DE HIPÓTESE DIEBOLD-MARIANO (Implementação Corrigida) ---\n",
    "    print(\"\\n--- RELATÓRIO 5: TESTE DE HIPÓTESE (p-valor, HORIZONTE MAIS LONGO) ---\")\n",
    "    display(Markdown(\"Comparando cada modelo com o **Híbrido (MIMO)**. Um p-valor < 0.05 (verde) indica que a performance do Híbrido é estatisticamente superior.\"))\n",
    "    \n",
    "    modelo_referencia = 'Híbrido (MIMO)'\n",
    "    df_teste_maior_h = df_results[df_results['horizonte'] == maior_horizonte]\n",
    "    dm_results = []\n",
    "\n",
    "    for dataset_nome, group in df_teste_maior_h.groupby('dataset'):\n",
    "        if modelo_referencia in group.columns and not group[modelo_referencia].isnull().all():\n",
    "            row = {'dataset': dataset_nome}\n",
    "            y_true_reais = group['y_true']\n",
    "            \n",
    "            for modelo_competidor in [m for m in modelos if m != modelo_referencia and m in group.columns and not group[m].isnull().all()]:\n",
    "                # Criar um df temporário para alinhar e remover NaNs do par específico\n",
    "                temp_df = pd.concat([y_true_reais, group[modelo_referencia], group[modelo_competidor]], axis=1, keys=['y_true', 'ref', 'comp']).dropna()\n",
    "                \n",
    "                if not temp_df.empty and len(temp_df) > 1:\n",
    "                    erros_ref = temp_df['y_true'] - temp_df['ref']\n",
    "                    erros_comp = temp_df['y_true'] - temp_df['comp']\n",
    "                    try:\n",
    "                        _, p_value = dm_test(erros_ref, erros_comp, alternative='less')\n",
    "                        row[modelo_competidor] = p_value\n",
    "                    except Exception as e:\n",
    "                        row[modelo_competidor] = np.nan\n",
    "                        print(f\"AVISO: Teste DM para {modelo_competidor} em {dataset_nome} falhou: {e}\")\n",
    "                else:\n",
    "                    row[modelo_competidor] = np.nan\n",
    "            dm_results.append(row)\n",
    "\n",
    "    if dm_results:\n",
    "        df_dm = pd.DataFrame(dm_results).set_index('dataset')\n",
    "        display(df_dm.style.format('{:.3f}').applymap(lambda x: 'background-color: lightgreen; font-weight: bold;' if pd.notna(x) and x < 0.05 else ''))\n",
    "    else:\n",
    "        print(\"Não foi possível gerar o relatório do teste Diebold-Mariano.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nERRO: Arquivo '{output_file}' não encontrado.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro ao gerar os relatórios: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybrid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
