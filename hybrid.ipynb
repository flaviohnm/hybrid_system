{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c96030f3be3e4a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T00:52:59.360703Z",
     "start_time": "2025-06-19T00:52:59.356446Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 1: IMPORTAÇÕES E SETUP GERAL\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9716172789275c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T00:52:59.414429Z",
     "start_time": "2025-06-19T00:52:59.376419Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "# Libs de Modelagem\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.datasets import get_rdataset\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS, MLP, LSTM, Autoformer\n",
    "\n",
    "# Libs de Avaliação\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7acde5f0e5c4b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 2: FUNÇÕES AUXILIARES (SETUP E PROCESSAMENTO)\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ff04ae19676ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def definir_seed(seed_value=42):\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68444ac84157ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_dataset(serie, dataset_name):\n",
    "    dir_path = \"./datasets/\"\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    file_path = os.path.join(dir_path, f\"{dataset_name.lower()}.csv\")\n",
    "    df = pd.DataFrame({\"date\": serie.index, \"value\": serie.values})\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"-> Cópia do dataset '{dataset_name}' salva em: {file_path}\")\n",
    "\n",
    "def carregar_serie(nome):\n",
    "    print(f\"Buscando dados de '{nome}' via statsmodels...\")\n",
    "    nome_base = nome.lower()\n",
    "\n",
    "    if nome_base == \"airpassengers\":\n",
    "        df = get_rdataset(\"AirPassengers\", package=\"datasets\").data\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1949-01-01\", periods=len(df), freq=\"MS\"),\n",
    "                          name=\"AirPassengers\")\n",
    "    elif nome_base == \"lynx\":\n",
    "        df = get_rdataset(\"lynx\", package=\"datasets\").data\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1821\", periods=len(df), freq=\"A\"), name=\"Lynx\")\n",
    "    elif nome_base == \"co2\":\n",
    "        df = get_rdataset(\"CO2\", package=\"datasets\").data\n",
    "        df = df.ffill()\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1958-03-29\", periods=len(df), freq=\"MS\"),\n",
    "                          name=\"CO2\")\n",
    "    elif nome_base == \"sunspots\":\n",
    "        df = get_rdataset(\"sunspots\", package=\"datasets\").data\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1749-01-01\", periods=len(df), freq=\"MS\"),\n",
    "                          name=\"Sunspots\")\n",
    "    elif nome_base == \"austres\":\n",
    "        df = get_rdataset(\"austres\", package=\"datasets\").data\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1971-03-01\", periods=len(df), freq=\"QS-MAR\"),\n",
    "                          name=\"AustralianResidents\")\n",
    "    elif nome_base == \"nottem\":\n",
    "        df = get_rdataset(\"nottem\", package=\"datasets\").data\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1920-01-01\", periods=len(df), freq=\"MS\"),\n",
    "                          name=\"Nottingham\")\n",
    "    else:\n",
    "        raise ValueError(f\"Série '{nome}' não reconhecida.\")\n",
    "\n",
    "    salvar_dataset(serie, nome)\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a220cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_serie_temporal(serie, percentual_treino=0.7, percentual_validacao=0.15):\n",
    "    tamanho_total = len(serie)\n",
    "    if tamanho_total < 20: \n",
    "        percentual_treino=0.8\n",
    "        percentual_validacao=0.0\n",
    "    ponto_corte_treino = int(tamanho_total * percentual_treino)\n",
    "    ponto_corte_validacao = int(tamanho_total * (percentual_treino + percentual_validacao))\n",
    "    treino = serie.iloc[:ponto_corte_treino]\n",
    "    validacao = serie.iloc[ponto_corte_treino:ponto_corte_validacao]\n",
    "    teste = serie.iloc[ponto_corte_validacao:]\n",
    "    return treino, validacao, teste\n",
    "\n",
    "def preparar_dados_para_neuralforecast(serie, nome_serie):\n",
    "    df = serie.reset_index()\n",
    "    df.columns = ['ds', 'y']\n",
    "    df['unique_id'] = nome_serie\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "767138d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 3: FUNÇÕES PARA CÁLCULO DE MÉTRICAS E MODELAGEM\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c38b31116385f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas(y_true, y_pred, y_train):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100 if np.all(y_true != 0) else np.inf\n",
    "    n = len(y_train)\n",
    "    d = np.sum(np.abs(y_train[1:] - y_train[:-1])) / (n - 1) if n > 1 else np.nan\n",
    "    mase = np.mean(np.abs(y_true - y_pred)) / d if d is not np.nan and d > 0 else np.inf\n",
    "    return {'RMSE': rmse, 'MAPE(%)': mape, 'MASE': mase}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcc9d2b54e19eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 4: PIPELINE DE EXPERIMENTO COM TREINO-VALIDAÇÃO-TESTE\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "330a2a71e0b1c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executar_experimento(nome_da_serie):\n",
    "    \"\"\"\n",
    "    Executa o pipeline completo com metodologia Treino-Validação-Teste para todos os modelos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # --- Configurações ---\n",
    "        ORDEM_ARIMA_FIXA = (3, 1, 2)\n",
    "        SEED = 42\n",
    "        MAX_INPUT_SIZE = 50\n",
    "        MAX_STEPS_NEURAL = 100\n",
    "\n",
    "        definir_seed(SEED)\n",
    "        \n",
    "        # --- Preparação dos Dados ---\n",
    "        serie_completa = carregar_serie(nome_da_serie)\n",
    "        treino, validacao, teste = dividir_serie_temporal(serie_completa)\n",
    "        \n",
    "        if len(teste) < 2 or len(validacao) < 2: \n",
    "            print(f\"AVISO: Dataset '{nome_da_serie}' muito pequeno para a divisão. Pulando.\")\n",
    "            return None, None\n",
    "\n",
    "        freq = serie_completa.index.freqstr or pd.infer_freq(serie_completa.index)\n",
    "        if freq is None: \n",
    "            print(f\"ERRO: Frequência não determinada para '{nome_da_serie}'.\")\n",
    "            return None, None\n",
    "\n",
    "        # Prepara os dados de treino uma vez para os modelos neurais\n",
    "        df_treino_nf = preparar_dados_para_neuralforecast(treino, nome_da_serie)\n",
    "        \n",
    "        # Listas para guardar os resultados de cada etapa\n",
    "        resultados_validacao = []\n",
    "        resultados_teste = []\n",
    "\n",
    "        # --- 1. Modelo ARIMA ---\n",
    "        try:\n",
    "            print(\"\\nProcessando: ARIMA\")\n",
    "            modelo_arima = ARIMA(treino.asfreq(freq), order=ORDEM_ARIMA_FIXA).fit()\n",
    "            # Prevê ambos os períodos: validação e teste\n",
    "            preds_futuro_arima = modelo_arima.predict(start=validacao.index[0], end=teste.index[-1])\n",
    "            preds_valid_arima = preds_futuro_arima[:len(validacao)]\n",
    "            preds_teste_arima = preds_futuro_arima[-len(teste):]\n",
    "\n",
    "            # Avalia na validação e no teste\n",
    "            metricas_val = calcular_metricas(validacao.values, preds_valid_arima.values, treino.values); metricas_val['modelo'] = 'ARIMA'; resultados_validacao.append(metricas_val)\n",
    "            metricas_test = calcular_metricas(teste.values, preds_teste_arima.values, treino.values); metricas_test['modelo'] = 'ARIMA'; resultados_teste.append(metricas_test)\n",
    "        except Exception as e:\n",
    "            print(f\"AVISO: Modelo ARIMA falhou: {e}\")\n",
    "\n",
    "        # --- 2. Modelos Neurais Puros ---\n",
    "        horizonte_total = len(validacao) + len(teste)\n",
    "        input_size = min(2 * horizonte_total, MAX_INPUT_SIZE)\n",
    "        modelos_para_testar = {'N-BEATS': NBEATS, 'MLP': MLP, 'LSTM': LSTM, 'Autoformer': Autoformer}\n",
    "\n",
    "        for nome_modelo, classe_modelo in modelos_para_testar.items():\n",
    "            try:\n",
    "                print(f\"Processando: {nome_modelo}\")\n",
    "                modelo_neural = [classe_modelo(input_size=input_size, h=horizonte_total, max_steps=MAX_STEPS_NEURAL, scaler_type='standard', random_seed=SEED)]\n",
    "                nf = NeuralForecast(models=modelo_neural, freq=freq)\n",
    "                nf.fit(df=df_treino_nf)\n",
    "                preds_futuro_df = nf.predict()\n",
    "                \n",
    "                # Separa as previsões para validação e teste\n",
    "                preds_valid_neural = preds_futuro_df[nome_modelo].values[:len(validacao)]\n",
    "                preds_teste_neural = preds_futuro_df[nome_modelo].values[-len(teste):]\n",
    "\n",
    "                # Avalia em ambas as etapas\n",
    "                metricas_val = calcular_metricas(validacao.values, preds_valid_neural, treino.values); metricas_val['modelo'] = f'{nome_modelo} (MIMO)'; resultados_validacao.append(metricas_val)\n",
    "                metricas_test = calcular_metricas(teste.values, preds_teste_neural, treino.values); metricas_test['modelo'] = f'{nome_modelo} (MIMO)'; resultados_teste.append(metricas_test)\n",
    "            except Exception as e:\n",
    "                print(f\"AVISO: Modelo {nome_modelo} falhou: {e}\")\n",
    "\n",
    "        # --- 3. Modelo Híbrido ---\n",
    "        if 'modelo_arima' in locals():\n",
    "            try:\n",
    "                print(\"Processando: Modelo Híbrido (HyS-MF)\")\n",
    "                residuos_treino = modelo_arima.resid\n",
    "                df_residuos_treino_nf = preparar_dados_para_neuralforecast(residuos_treino, \"residuos\")\n",
    "                modelo_residuos = [NBEATS(input_size=input_size, h=horizonte_total, max_steps=MAX_STEPS_NEURAL, scaler_type='standard', random_seed=SEED)]\n",
    "                nf_residuos = NeuralForecast(models=modelo_residuos, freq=freq)\n",
    "                nf_residuos.fit(df=df_residuos_treino_nf)\n",
    "                preds_residuos_futuro = nf_residuos.predict()['NBEATS'].values\n",
    "                \n",
    "                # Separa as previsões de resíduos\n",
    "                preds_residuos_valid = preds_residuos_futuro[:len(validacao)]\n",
    "                preds_residuos_teste = preds_residuos_futuro[-len(teste):]\n",
    "\n",
    "                # Previsão híbrida para validação e teste\n",
    "                preds_hibrido_valid = preds_valid_arima.values + preds_residuos_valid\n",
    "                preds_hibrido_teste = preds_teste_arima.values + preds_residuos_teste\n",
    "\n",
    "                # Avalia em ambas as etapas\n",
    "                metricas_val = calcular_metricas(validacao.values, preds_hibrido_valid, treino.values); metricas_val['modelo'] = 'Híbrido (HyS-MF)'; resultados_validacao.append(metricas_val)\n",
    "                metricas_test = calcular_metricas(teste.values, preds_hibrido_teste, treino.values); metricas_test['modelo'] = 'Híbrido (HyS-MF)'; resultados_teste.append(metricas_test)\n",
    "            except Exception as e:\n",
    "                print(f\"AVISO: Modelo Híbrido falhou: {e}\")\n",
    "\n",
    "        return pd.DataFrame(resultados_validacao), pd.DataFrame(resultados_teste)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO GERAL no processamento do dataset '{nome_da_serie}': {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "189a54af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 4: ORQUESTRADOR E RELATÓRIO FINAL\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8886be65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando todos os datasets:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando dados de 'AirPassengers' via statsmodels...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Cópia do dataset 'AirPassengers' salva em: ./datasets\\airpassengers.csv\n",
      "\n",
      "Processando: ARIMA\n",
      "Processando: N-BEATS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.6 M  | train\n",
      "-------------------------------------------------------\n",
      "2.6 M     Trainable params\n",
      "8.4 K     Non-trainable params\n",
      "2.6 M     Total params\n",
      "10.361    Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=1483, train_loss_step=0.0222, train_loss_epoch=0.0222]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s, v_num=1483, train_loss_step=0.0222, train_loss_epoch=0.0222]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AVISO: Modelo N-BEATS falhou: 'N-BEATS'\n",
      "Processando: MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | mlp          | ModuleList    | 1.1 M  | train\n",
      "4 | out          | Linear        | 45.1 K | train\n",
      "-------------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.588     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=1485, train_loss_step=0.0478, train_loss_epoch=0.0478]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=1485, train_loss_step=0.0478, train_loss_epoch=0.0478]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 44.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type          | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | loss            | MAE           | 0      | train\n",
      "1 | padder          | ConstantPad1d | 0      | train\n",
      "2 | scaler          | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "4 | context_adapter | Linear        | 88.4 K | train\n",
      "5 | mlp_decoder     | MLP           | 2.4 K  | train\n",
      "----------------------------------------------------------\n",
      "574 K     Trainable params\n",
      "0         Non-trainable params\n",
      "574 K     Total params\n",
      "2.299     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 13.38it/s, v_num=1487, train_loss_step=0.367, train_loss_epoch=0.367]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s, v_num=1487, train_loss_step=0.367, train_loss_epoch=0.367]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 31.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: Autoformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | decomp        | SeriesDecomp  | 0      | train\n",
      "4 | enc_embedding | DataEmbedding | 384    | train\n",
      "5 | dec_embedding | DataEmbedding | 384    | train\n",
      "6 | encoder       | Encoder       | 148 K  | train\n",
      "7 | decoder       | Decoder       | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "290 K     Trainable params\n",
      "0         Non-trainable params\n",
      "290 K     Total params\n",
      "1.162     Total estimated model params size (MB)\n",
      "85        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:09<00:00,  0.11it/s, v_num=1489, train_loss_step=0.718, train_loss_epoch=0.718]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:09<00:00,  0.11it/s, v_num=1489, train_loss_step=0.718, train_loss_epoch=0.718]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 19.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: Modelo Híbrido (HyS-MF)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.6 M  | train\n",
      "-------------------------------------------------------\n",
      "2.6 M     Trainable params\n",
      "8.4 K     Non-trainable params\n",
      "2.6 M     Total params\n",
      "10.361    Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s, v_num=1491, train_loss_step=0.0207, train_loss_epoch=0.0207]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  3.37it/s, v_num=1491, train_loss_step=0.0207, train_loss_epoch=0.0207]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando todos os datasets:  33%|███▎      | 1/3 [18:20<36:41, 1100.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Buscando dados de 'co2' via statsmodels...\n",
      "-> Cópia do dataset 'co2' salva em: ./datasets\\co2.csv\n",
      "\n",
      "Processando: ARIMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando: N-BEATS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.9 M  | train\n",
      "-------------------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "54.1 K    Non-trainable params\n",
      "2.9 M     Total params\n",
      "11.539    Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  3.29it/s, v_num=1493, train_loss_step=0.217, train_loss_epoch=0.217]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  3.21it/s, v_num=1493, train_loss_step=0.217, train_loss_epoch=0.217]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AVISO: Modelo N-BEATS falhou: 'N-BEATS'\n",
      "Processando: MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | mlp          | ModuleList    | 1.1 M  | train\n",
      "4 | out          | Linear        | 144 K  | train\n",
      "-------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.985     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=1495, train_loss_step=0.205, train_loss_epoch=0.205]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=1495, train_loss_step=0.205, train_loss_epoch=0.205]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type          | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | loss            | MAE           | 0      | train\n",
      "1 | padder          | ConstantPad1d | 0      | train\n",
      "2 | scaler          | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "4 | context_adapter | Linear        | 283 K  | train\n",
      "5 | mlp_decoder     | MLP           | 2.4 K  | train\n",
      "----------------------------------------------------------\n",
      "769 K     Trainable params\n",
      "0         Non-trainable params\n",
      "769 K     Total params\n",
      "3.079     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 11.10it/s, v_num=1497, train_loss_step=0.307, train_loss_epoch=0.307]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 10.24it/s, v_num=1497, train_loss_step=0.307, train_loss_epoch=0.307]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: Autoformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | decomp        | SeriesDecomp  | 0      | train\n",
      "4 | enc_embedding | DataEmbedding | 384    | train\n",
      "5 | dec_embedding | DataEmbedding | 384    | train\n",
      "6 | encoder       | Encoder       | 148 K  | train\n",
      "7 | decoder       | Decoder       | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "290 K     Trainable params\n",
      "0         Non-trainable params\n",
      "290 K     Total params\n",
      "1.162     Total estimated model params size (MB)\n",
      "85        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:18<00:00,  0.05it/s, v_num=1499, train_loss_step=2.610, train_loss_epoch=2.610]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:18<00:00,  0.05it/s, v_num=1499, train_loss_step=2.610, train_loss_epoch=2.610]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: Modelo Híbrido (HyS-MF)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.9 M  | train\n",
      "-------------------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "54.1 K    Non-trainable params\n",
      "2.9 M     Total params\n",
      "11.539    Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s, v_num=1501, train_loss_step=0.111, train_loss_epoch=0.111]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s, v_num=1501, train_loss_step=0.111, train_loss_epoch=0.111]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.79it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando todos os datasets:  67%|██████▋   | 2/3 [1:38:38<54:47, 3287.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Buscando dados de 'lynx' via statsmodels...\n",
      "-> Cópia do dataset 'lynx' salva em: ./datasets\\lynx.csv\n",
      "\n",
      "Processando: ARIMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando: N-BEATS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.6 M  | train\n",
      "-------------------------------------------------------\n",
      "2.6 M     Trainable params\n",
      "6.0 K     Non-trainable params\n",
      "2.6 M     Total params\n",
      "10.259    Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s, v_num=1503, train_loss_step=0.0128, train_loss_epoch=0.0128]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, v_num=1503, train_loss_step=0.0128, train_loss_epoch=0.0128]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 44.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AVISO: Modelo N-BEATS falhou: 'N-BEATS'\n",
      "Processando: MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | mlp          | ModuleList    | 1.1 M  | train\n",
      "4 | out          | Linear        | 35.9 K | train\n",
      "-------------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.551     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=1505, train_loss_step=0.030, train_loss_epoch=0.030]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s, v_num=1505, train_loss_step=0.030, train_loss_epoch=0.030]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.89it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type          | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | loss            | MAE           | 0      | train\n",
      "1 | padder          | ConstantPad1d | 0      | train\n",
      "2 | scaler          | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "4 | context_adapter | Linear        | 70.4 K | train\n",
      "5 | mlp_decoder     | MLP           | 2.4 K  | train\n",
      "----------------------------------------------------------\n",
      "556 K     Trainable params\n",
      "0         Non-trainable params\n",
      "556 K     Total params\n",
      "2.227     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 12.41it/s, v_num=1507, train_loss_step=0.436, train_loss_epoch=0.436]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 11.29it/s, v_num=1507, train_loss_step=0.436, train_loss_epoch=0.436]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 32.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: Autoformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | decomp        | SeriesDecomp  | 0      | train\n",
      "4 | enc_embedding | DataEmbedding | 384    | train\n",
      "5 | dec_embedding | DataEmbedding | 384    | train\n",
      "6 | encoder       | Encoder       | 148 K  | train\n",
      "7 | decoder       | Decoder       | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "290 K     Trainable params\n",
      "0         Non-trainable params\n",
      "290 K     Total params\n",
      "1.162     Total estimated model params size (MB)\n",
      "85        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:08<00:00,  0.12it/s, v_num=1509, train_loss_step=0.326, train_loss_epoch=0.326]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:08<00:00,  0.12it/s, v_num=1509, train_loss_step=0.326, train_loss_epoch=0.326]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: Modelo Híbrido (HyS-MF)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.6 M  | train\n",
      "-------------------------------------------------------\n",
      "2.6 M     Trainable params\n",
      "6.0 K     Non-trainable params\n",
      "2.6 M     Total params\n",
      "10.259    Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  3.49it/s, v_num=1511, train_loss_step=0.0173, train_loss_epoch=0.0173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  3.37it/s, v_num=1511, train_loss_step=0.0173, train_loss_epoch=0.0173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando todos os datasets: 100%|██████████| 3/3 [1:54:10<00:00, 2283.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Arquivo 'resultados_validacao.csv' salvo com sucesso!\n",
      "Arquivo 'resultados_teste.csv' salvo com sucesso!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "LISTA_DE_DATASETS = ['AirPassengers', 'co2', 'lynx'] # Usando uma lista menor para exemplo\n",
    "resultados_validacao_geral = []\n",
    "resultados_teste_geral = []\n",
    "\n",
    "for dataset in tqdm(LISTA_DE_DATASETS, desc=\"Processando todos os datasets\"):\n",
    "    df_validacao, df_teste = executar_experimento(dataset)\n",
    "    \n",
    "    if df_validacao is not None and not df_validacao.empty:\n",
    "        df_validacao['dataset'] = dataset\n",
    "        resultados_validacao_geral.append(df_validacao)\n",
    "        \n",
    "    if df_teste is not None and not df_teste.empty:\n",
    "        df_teste['dataset'] = dataset\n",
    "        resultados_teste_geral.append(df_teste)\n",
    "\n",
    "# --- Salvando os resultados em arquivos CSV ---\n",
    "if resultados_validacao_geral:\n",
    "    df_validacao_final = pd.concat(resultados_validacao_geral)\n",
    "    df_validacao_final.to_csv(\"./datasets/silver/resultados_validacao.csv\", index=False)\n",
    "    print(\"\\nArquivo 'resultados_validacao.csv' salvo com sucesso!\")\n",
    "\n",
    "if resultados_teste_geral:\n",
    "    df_teste_final = pd.concat(resultados_teste_geral)\n",
    "    df_teste_final.to_csv(\"./datasets/silver/resultados_teste.csv\", index=False)\n",
    "    print(\"Arquivo 'resultados_teste.csv' salvo com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b98ae8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# SEÇÃO 5: GERAÇÃO DE RELATÓRIOS A PARTIR DOS ARQUIVOS SALVOS\n",
    "# ================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7848bb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================\n",
      "     GERANDO RELATÓRIOS A PARTIR DOS DADOS SALVOS\n",
      "============================================================\n",
      "\n",
      "--- RELATÓRIO 1: DESEMPENHO FINAL (TESTE) POR MÉTRICA ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2dfdc_row3_col0, #T_2dfdc_row3_col1, #T_2dfdc_row3_col2, #T_2dfdc_row6_col0, #T_2dfdc_row6_col1, #T_2dfdc_row6_col2, #T_2dfdc_row11_col0, #T_2dfdc_row11_col1, #T_2dfdc_row11_col2 {\n",
       "  background-color: #4285F4;\n",
       "  color: white;\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2dfdc\">\n",
       "  <caption>O destaque indica o melhor modelo para cada métrica no conjunto de teste.</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2dfdc_level0_col0\" class=\"col_heading level0 col0\" >Mean RMSE</th>\n",
       "      <th id=\"T_2dfdc_level0_col1\" class=\"col_heading level0 col1\" >Mean MAPE(%)</th>\n",
       "      <th id=\"T_2dfdc_level0_col2\" class=\"col_heading level0 col2\" >Mean MASE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >dataset</th>\n",
       "      <th class=\"index_name level1\" >Modelo</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfdc_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"5\">AirPassengers</th>\n",
       "      <th id=\"T_2dfdc_level1_row0\" class=\"row_heading level1 row0\" >ARIMA</th>\n",
       "      <td id=\"T_2dfdc_row0_col0\" class=\"data row0 col0\" >151.779</td>\n",
       "      <td id=\"T_2dfdc_row0_col1\" class=\"data row0 col1\" >27.496</td>\n",
       "      <td id=\"T_2dfdc_row0_col2\" class=\"data row0 col2\" >7.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfdc_level1_row1\" class=\"row_heading level1 row1\" >MLP (MIMO)</th>\n",
       "      <td id=\"T_2dfdc_row1_col0\" class=\"data row1 col0\" >91.366</td>\n",
       "      <td id=\"T_2dfdc_row1_col1\" class=\"data row1 col1\" >18.633</td>\n",
       "      <td id=\"T_2dfdc_row1_col2\" class=\"data row1 col2\" >4.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfdc_level1_row2\" class=\"row_heading level1 row2\" >LSTM (MIMO)</th>\n",
       "      <td id=\"T_2dfdc_row2_col0\" class=\"data row2 col0\" >111.488</td>\n",
       "      <td id=\"T_2dfdc_row2_col1\" class=\"data row2 col1\" >17.067</td>\n",
       "      <td id=\"T_2dfdc_row2_col2\" class=\"data row2 col2\" >4.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfdc_level1_row3\" class=\"row_heading level1 row3\" >Autoformer (MIMO)</th>\n",
       "      <td id=\"T_2dfdc_row3_col0\" class=\"data row3 col0\" >65.523</td>\n",
       "      <td id=\"T_2dfdc_row3_col1\" class=\"data row3 col1\" >12.419</td>\n",
       "      <td id=\"T_2dfdc_row3_col2\" class=\"data row3 col2\" >3.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfdc_level1_row4\" class=\"row_heading level1 row4\" >Híbrido (HyS-MF)</th>\n",
       "      <td id=\"T_2dfdc_row4_col0\" class=\"data row4 col0\" >149.034</td>\n",
       "      <td id=\"T_2dfdc_row4_col1\" class=\"data row4 col1\" >27.350</td>\n",
       "      <td id=\"T_2dfdc_row4_col2\" class=\"data row4 col2\" >7.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfdc_level0_row5\" class=\"row_heading level0 row5\" rowspan=\"5\">co2</th>\n",
       "      <th id=\"T_2dfdc_level1_row5\" class=\"row_heading level1 row5\" >ARIMA</th>\n",
       "      <td id=\"T_2dfdc_row5_col0\" class=\"data row5 col0\" >14.476</td>\n",
       "      <td id=\"T_2dfdc_row5_col1\" class=\"data row5 col1\" >3.899</td>\n",
       "      <td id=\"T_2dfdc_row5_col2\" class=\"data row5 col2\" >13.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfdc_level1_row6\" class=\"row_heading level1 row6\" >MLP (MIMO)</th>\n",
       "      <td id=\"T_2dfdc_row6_col0\" class=\"data row6 col0\" >1.248</td>\n",
       "      <td id=\"T_2dfdc_row6_col1\" class=\"data row6 col1\" >0.311</td>\n",
       "      <td id=\"T_2dfdc_row6_col2\" class=\"data row6 col2\" >1.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfdc_level1_row7\" class=\"row_heading level1 row7\" >LSTM (MIMO)</th>\n",
       "      <td id=\"T_2dfdc_row7_col0\" class=\"data row7 col0\" >27.378</td>\n",
       "      <td id=\"T_2dfdc_row7_col1\" class=\"data row7 col1\" >7.565</td>\n",
       "      <td id=\"T_2dfdc_row7_col2\" class=\"data row7 col2\" >26.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfdc_level1_row8\" class=\"row_heading level1 row8\" >Autoformer (MIMO)</th>\n",
       "      <td id=\"T_2dfdc_row8_col0\" class=\"data row8 col0\" >14.688</td>\n",
       "      <td id=\"T_2dfdc_row8_col1\" class=\"data row8 col1\" >3.922</td>\n",
       "      <td id=\"T_2dfdc_row8_col2\" class=\"data row8 col2\" >13.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfdc_level1_row9\" class=\"row_heading level1 row9\" >Híbrido (HyS-MF)</th>\n",
       "      <td id=\"T_2dfdc_row9_col0\" class=\"data row9 col0\" >14.247</td>\n",
       "      <td id=\"T_2dfdc_row9_col1\" class=\"data row9 col1\" >3.835</td>\n",
       "      <td id=\"T_2dfdc_row9_col2\" class=\"data row9 col2\" >13.332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfdc_level0_row10\" class=\"row_heading level0 row10\" rowspan=\"5\">lynx</th>\n",
       "      <th id=\"T_2dfdc_level1_row10\" class=\"row_heading level1 row10\" >ARIMA</th>\n",
       "      <td id=\"T_2dfdc_row10_col0\" class=\"data row10 col0\" >1156.889</td>\n",
       "      <td id=\"T_2dfdc_row10_col1\" class=\"data row10 col1\" >330.568</td>\n",
       "      <td id=\"T_2dfdc_row10_col2\" class=\"data row10 col2\" >1.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfdc_level1_row11\" class=\"row_heading level1 row11\" >MLP (MIMO)</th>\n",
       "      <td id=\"T_2dfdc_row11_col0\" class=\"data row11 col0\" >1085.519</td>\n",
       "      <td id=\"T_2dfdc_row11_col1\" class=\"data row11 col1\" >77.203</td>\n",
       "      <td id=\"T_2dfdc_row11_col2\" class=\"data row11 col2\" >0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfdc_level1_row12\" class=\"row_heading level1 row12\" >LSTM (MIMO)</th>\n",
       "      <td id=\"T_2dfdc_row12_col0\" class=\"data row12 col0\" >1152.840</td>\n",
       "      <td id=\"T_2dfdc_row12_col1\" class=\"data row12 col1\" >110.882</td>\n",
       "      <td id=\"T_2dfdc_row12_col2\" class=\"data row12 col2\" >1.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfdc_level1_row13\" class=\"row_heading level1 row13\" >Autoformer (MIMO)</th>\n",
       "      <td id=\"T_2dfdc_row13_col0\" class=\"data row13 col0\" >1453.023</td>\n",
       "      <td id=\"T_2dfdc_row13_col1\" class=\"data row13 col1\" >148.815</td>\n",
       "      <td id=\"T_2dfdc_row13_col2\" class=\"data row13 col2\" >1.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfdc_level1_row14\" class=\"row_heading level1 row14\" >Híbrido (HyS-MF)</th>\n",
       "      <td id=\"T_2dfdc_row14_col0\" class=\"data row14 col0\" >1180.743</td>\n",
       "      <td id=\"T_2dfdc_row14_col1\" class=\"data row14 col1\" >254.330</td>\n",
       "      <td id=\"T_2dfdc_row14_col2\" class=\"data row14 col2\" >1.169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2f2ed447250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RELATÓRIO 2: RANKING DOS MODELOS (BASEADO EM RMSE DE TESTE) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f7ac8_row0_col1, #T_f7ac8_row1_col4, #T_f7ac8_row2_col4, #T_f7ac8_row3_col4 {\n",
       "  background-color: #4285F4;\n",
       "  color: white;\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f7ac8\">\n",
       "  <caption>Ranking dos modelos (1 = Melhor, ...).</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Modelo</th>\n",
       "      <th id=\"T_f7ac8_level0_col0\" class=\"col_heading level0 col0\" >ARIMA</th>\n",
       "      <th id=\"T_f7ac8_level0_col1\" class=\"col_heading level0 col1\" >Autoformer (MIMO)</th>\n",
       "      <th id=\"T_f7ac8_level0_col2\" class=\"col_heading level0 col2\" >Híbrido (HyS-MF)</th>\n",
       "      <th id=\"T_f7ac8_level0_col3\" class=\"col_heading level0 col3\" >LSTM (MIMO)</th>\n",
       "      <th id=\"T_f7ac8_level0_col4\" class=\"col_heading level0 col4\" >MLP (MIMO)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >dataset</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f7ac8_level0_row0\" class=\"row_heading level0 row0\" >AirPassengers</th>\n",
       "      <td id=\"T_f7ac8_row0_col0\" class=\"data row0 col0\" >5.0</td>\n",
       "      <td id=\"T_f7ac8_row0_col1\" class=\"data row0 col1\" >1.0</td>\n",
       "      <td id=\"T_f7ac8_row0_col2\" class=\"data row0 col2\" >4.0</td>\n",
       "      <td id=\"T_f7ac8_row0_col3\" class=\"data row0 col3\" >3.0</td>\n",
       "      <td id=\"T_f7ac8_row0_col4\" class=\"data row0 col4\" >2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7ac8_level0_row1\" class=\"row_heading level0 row1\" >co2</th>\n",
       "      <td id=\"T_f7ac8_row1_col0\" class=\"data row1 col0\" >3.0</td>\n",
       "      <td id=\"T_f7ac8_row1_col1\" class=\"data row1 col1\" >4.0</td>\n",
       "      <td id=\"T_f7ac8_row1_col2\" class=\"data row1 col2\" >2.0</td>\n",
       "      <td id=\"T_f7ac8_row1_col3\" class=\"data row1 col3\" >5.0</td>\n",
       "      <td id=\"T_f7ac8_row1_col4\" class=\"data row1 col4\" >1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7ac8_level0_row2\" class=\"row_heading level0 row2\" >lynx</th>\n",
       "      <td id=\"T_f7ac8_row2_col0\" class=\"data row2 col0\" >3.0</td>\n",
       "      <td id=\"T_f7ac8_row2_col1\" class=\"data row2 col1\" >5.0</td>\n",
       "      <td id=\"T_f7ac8_row2_col2\" class=\"data row2 col2\" >4.0</td>\n",
       "      <td id=\"T_f7ac8_row2_col3\" class=\"data row2 col3\" >2.0</td>\n",
       "      <td id=\"T_f7ac8_row2_col4\" class=\"data row2 col4\" >1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7ac8_level0_row3\" class=\"row_heading level0 row3\" >Média do Rank</th>\n",
       "      <td id=\"T_f7ac8_row3_col0\" class=\"data row3 col0\" >3.7</td>\n",
       "      <td id=\"T_f7ac8_row3_col1\" class=\"data row3 col1\" >3.3</td>\n",
       "      <td id=\"T_f7ac8_row3_col2\" class=\"data row3 col2\" >3.3</td>\n",
       "      <td id=\"T_f7ac8_row3_col3\" class=\"data row3 col3\" >3.3</td>\n",
       "      <td id=\"T_f7ac8_row3_col4\" class=\"data row3 col4\" >1.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2f2ed555de0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"     GERANDO RELATÓRIOS A PARTIR DOS DADOS SALVOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    # Carrega os resultados do teste a partir do arquivo\n",
    "    df_final_comparativo = pd.read_csv(\"resultados_teste.csv\").rename(columns={'modelo': 'Modelo'})\n",
    "    \n",
    "    # Renomeia as colunas para o relatório\n",
    "    rename_dict = {'RMSE': 'Mean RMSE', 'MAPE(%)': 'Mean MAPE(%)', 'MASE': 'Mean MASE'}\n",
    "    df_final_comparativo.rename(columns=rename_dict, inplace=True)\n",
    "    \n",
    "    # --- Relatório 1: Tabela de Desempenho (baseado nos dados de TESTE) ---\n",
    "    print(\"\\n--- RELATÓRIO 1: DESEMPENHO FINAL (TESTE) POR MÉTRICA ---\")\n",
    "\n",
    "    def destacar_melhor_por_grupo(df):\n",
    "        df_style = pd.DataFrame('', index=df.index, columns=df.columns)\n",
    "        estilo_melhor = 'background-color: #4285F4; color: white; font-weight: bold;'\n",
    "        for metrica in ['Mean RMSE', 'Mean MAPE(%)', 'Mean MASE']:\n",
    "            if metrica in df.columns:\n",
    "                idx_minimos = df.groupby('dataset')[metrica].idxmin()\n",
    "                df_style.loc[idx_minimos, metrica] = estilo_melhor\n",
    "        return df_style\n",
    "\n",
    "    df_reporte_1 = df_final_comparativo.set_index(['dataset', 'Modelo'])\n",
    "    \n",
    "    styled_report_1 = (df_reporte_1.style\n",
    "                       .format('{:.3f}')\n",
    "                       .set_caption(\"O destaque indica o melhor modelo para cada métrica no conjunto de teste.\")\n",
    "                       .apply(destacar_melhor_por_grupo, axis=None))\n",
    "    \n",
    "    display(styled_report_1)\n",
    "\n",
    "    # --- Relatório 2: Tabela de Ranking (baseado nos dados de TESTE) ---\n",
    "    print(\"\\n--- RELATÓRIO 2: RANKING DOS MODELOS (BASEADO EM RMSE DE TESTE) ---\")\n",
    "    \n",
    "    df_final_comparativo['Rank'] = df_final_comparativo.groupby('dataset')['Mean RMSE'].rank().astype(int)\n",
    "    df_pivot_rank = df_final_comparativo.pivot(index='dataset', columns='Modelo', values='Rank')\n",
    "    df_pivot_rank.loc['Média do Rank'] = df_pivot_rank.mean(axis=0)\n",
    "\n",
    "    styled_report_2 = (df_pivot_rank.style\n",
    "                       .format('{:.1f}')\n",
    "                       .highlight_min(axis=1, props='background-color: #4285F4; color: white; font-weight: bold;')\n",
    "                       .set_caption(\"Ranking dos modelos (1 = Melhor, ...).\"))\n",
    "    \n",
    "    display(styled_report_2)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"\\nERRO: Arquivo 'resultados_teste.csv' não encontrado.\")\n",
    "    print(\"Por favor, execute a Seção 4 (Etapa de Execução e Salvamento) primeiro para gerar os resultados.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybrid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
