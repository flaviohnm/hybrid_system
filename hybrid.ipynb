{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c96030f3be3e4a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T00:52:59.360703Z",
     "start_time": "2025-06-19T00:52:59.356446Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 1: IMPORTAÇÕES E SETUP GERAL\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9716172789275c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T00:52:59.414429Z",
     "start_time": "2025-06-19T00:52:59.376419Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "# Libs de Modelagem e Estatística\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.datasets import get_rdataset\n",
    "from dieboldmariano import dm_test\n",
    "import pmdarima as pm\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS, MLP, LSTM, Autoformer, NHITS\n",
    "\n",
    "# Libs de Avaliação\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7acde5f0e5c4b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 2: FUNÇÕES AUXILIARES (SETUP E PROCESSAMENTO)\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff04ae19676ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def definir_seed(seed_value=42):\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68444ac84157ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_dataset(serie, dataset_name):\n",
    "    dir_path = \"./data/bronze\"\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    file_path = os.path.join(dir_path, f\"{dataset_name.lower()}.csv\")\n",
    "    df = pd.DataFrame({\"date\": serie.index, \"value\": serie.values})\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"-> Cópia do dataset '{dataset_name}' salva em: {file_path}\")\n",
    "\n",
    "def carregar_serie(nome):\n",
    "    print(f\"Buscando dados de '{nome}' via statsmodels...\")\n",
    "    nome_base = nome.lower()\n",
    "\n",
    "    if nome_base == \"airpassengers\":\n",
    "        df = get_rdataset(\"AirPassengers\", package=\"datasets\").data\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1949-01-01\", periods=len(df), freq=\"MS\"),\n",
    "                          name=\"AirPassengers\")\n",
    "    elif nome_base == \"lynx\":\n",
    "        df = get_rdataset(\"lynx\", package=\"datasets\").data\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1821\", periods=len(df), freq=\"A\"), name=\"Lynx\")\n",
    "    elif nome_base == \"co2\":\n",
    "        df = get_rdataset(\"CO2\", package=\"datasets\").data\n",
    "        df = df.ffill()\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1958-03-29\", periods=len(df), freq=\"MS\"),\n",
    "                          name=\"CO2\")\n",
    "    elif nome_base == \"sunspots\":\n",
    "        df = get_rdataset(\"sunspots\", package=\"datasets\").data\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1749-01-01\", periods=len(df), freq=\"MS\"),\n",
    "                          name=\"Sunspots\")\n",
    "    elif nome_base == \"austres\":\n",
    "        df = get_rdataset(\"austres\", package=\"datasets\").data\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1971-03-01\", periods=len(df), freq=\"QS-MAR\"),\n",
    "                          name=\"AustralianResidents\")\n",
    "    elif nome_base == \"nottem\":\n",
    "        df = get_rdataset(\"nottem\", package=\"datasets\").data\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1920-01-01\", periods=len(df), freq=\"MS\"),\n",
    "                          name=\"Nottingham\")\n",
    "    else:\n",
    "        raise ValueError(f\"Lógica de download para a série '{nome}' não implementada.\")\n",
    "\n",
    "    salvar_dataset(serie, nome)\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a220cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_serie_temporal(serie, percentual_treino=0.85):\n",
    "    tamanho_total = len(serie)\n",
    "    ponto_corte_treino = int(tamanho_total * percentual_treino)\n",
    "    treino = serie.iloc[:ponto_corte_treino]\n",
    "    teste = serie.iloc[ponto_corte_treino:]\n",
    "    return treino, teste\n",
    "\n",
    "def preparar_dados_para_neuralforecast(serie, nome_serie):\n",
    "    df = serie.reset_index()\n",
    "    df.columns = ['ds', 'y']\n",
    "    df['unique_id'] = nome_serie\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "767138d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 3: FUNÇÕES PARA CÁLCULO DE MÉTRICAS E MODELAGEM\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c38b31116385f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas(y_true, y_pred, y_train):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100 if np.all(y_true != 0) else np.inf\n",
    "    n = len(y_train)\n",
    "    d = np.sum(np.abs(y_train[1:] - y_train[:-1])) / (n - 1) if n > 1 else np.nan\n",
    "    mase = np.mean(np.abs(y_true - y_pred)) / d if d is not np.nan and d > 0 else np.inf\n",
    "    return {'RMSE': rmse, 'MAPE(%)': mape, 'MASE': mase}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cae6b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 4: PIPELINE AVANÇADO PARA O ARIMA\n",
    "# =========================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcc9d2b54e19eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_melhor_arima_auto(treino_log, freq):\n",
    "    \"\"\"Usa auto_arima para encontrar a melhor ordem ARIMA, incluindo sazonalidade.\"\"\"\n",
    "    print(\"Buscando melhor ordem ARIMA com auto_arima...\")\n",
    "    m = 12 if freq.startswith('M') else (4 if freq.startswith('Q') else 1)\n",
    "    auto_arima_model = pm.auto_arima(treino_log, m=m, seasonal=True, trace=False, error_action='ignore', suppress_warnings=True, stepwise=True)\n",
    "    print(f\"Melhor ordem encontrada: {auto_arima_model.order} Sazonal: {auto_arima_model.seasonal_order}\")\n",
    "    return auto_arima_model.order, auto_arima_model.seasonal_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "189a54af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 5: PIPELINE DE EXPERIMENTO COMPLETO E AVANÇADO\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f7c9b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 3: PIPELINE DE EXPERIMENTO (COM CORREÇÃO NO ARIMA)\n",
    "# =========================================================\n",
    "\n",
    "def executar_experimento(nome_da_serie, horizonte):\n",
    "    \"\"\"\n",
    "    Executa o pipeline completo para um dataset e um horizonte específicos,\n",
    "    com a correção na função de previsão do ARIMA.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        SEED = 42; definir_seed(SEED)\n",
    "        MAX_INPUT_SIZE = 50 \n",
    "        MAX_STEPS_NEURAL = 150\n",
    "        \n",
    "        serie_original = carregar_serie(nome_da_serie)\n",
    "        \n",
    "        if len(serie_original) < horizonte + 50:\n",
    "            print(f\"AVISO: Série '{nome_da_serie}' muito curta para o horizonte {horizonte}. Pulando.\")\n",
    "            return None\n",
    "\n",
    "        percentual_treino = 1 - (horizonte / len(serie_original))\n",
    "        treino_orig, teste_orig = dividir_serie_temporal(serie_original, percentual_treino=percentual_treino)\n",
    "        \n",
    "        treino_log = np.log(treino_orig)\n",
    "        \n",
    "        freq = serie_original.index.freqstr or pd.infer_freq(serie_original.index)\n",
    "        if freq is None: return None\n",
    "\n",
    "        previsoes_teste = {'y_true': teste_orig.values}\n",
    "        input_size = min(2 * horizonte, MAX_INPUT_SIZE)\n",
    "        \n",
    "        # --- 1. Modelo ARIMA ---\n",
    "        modelo_arima = None\n",
    "        try:\n",
    "            print(f\"Processando: ARIMA para horizonte {horizonte}\")\n",
    "            ordem, ordem_sazonal = encontrar_melhor_arima_auto(treino_log, freq)\n",
    "            modelo_arima = ARIMA(treino_log.asfreq(freq), order=ordem, seasonal_order=ordem_sazonal).fit()\n",
    "            \n",
    "            # --- CORREÇÃO APLICADA AQUI ---\n",
    "            # Usamos .forecast() para prever 'h' passos à frente, em vez de .predict()\n",
    "            preds_log_teste_arima = modelo_arima.forecast(steps=horizonte)\n",
    "            previsoes_teste['ARIMA'] = np.exp(preds_log_teste_arima).values\n",
    "\n",
    "        except Exception as e: print(f\"AVISO: ARIMA falhou: {e}\")\n",
    "\n",
    "        # --- 2. Modelos Neurais Puros ---\n",
    "        df_treino_log_nf = preparar_dados_para_neuralforecast(treino_log, nome_da_serie)\n",
    "        for nome_modelo, classe_modelo in {'N-BEATS': NBEATS, 'MLP': MLP, 'LSTM': LSTM, 'Autoformer': Autoformer, 'NHITS': NHITS}.items():\n",
    "            try:\n",
    "                print(f\"Processando: {nome_modelo}\")\n",
    "                modelo_neural = [classe_modelo(input_size=input_size, h=horizonte, max_steps=MAX_STEPS_NEURAL, scaler_type='standard', random_seed=SEED)]\n",
    "                nf = NeuralForecast(models=modelo_neural, freq=freq)\n",
    "                nf.fit(df=df_treino_log_nf, verbose=False)\n",
    "                previsoes_teste[nome_modelo] = np.exp(nf.predict()[classe_modelo.__name__].values)\n",
    "            except Exception as e: print(f\"AVISO: {nome_modelo} falhou: {e}\")\n",
    "        \n",
    "        # --- 3. Modelo Híbrido ---\n",
    "        if 'ARIMA' in previsoes_teste and modelo_arima is not None:\n",
    "            try:\n",
    "                print(\"Processando: Híbrido (MIMO)\")\n",
    "                residuos_treino_log = modelo_arima.resid\n",
    "                df_residuos_nf = preparar_dados_para_neuralforecast(residuos_treino_log, \"residuos\")\n",
    "                modelo_residuos = [NBEATS(input_size=input_size, h=horizonte, max_steps=MAX_STEPS_NEURAL, scaler_type='standard', random_seed=SEED)]\n",
    "                nf_residuos = NeuralForecast(models=modelo_residuos, freq=freq)\n",
    "                nf_residuos.fit(df=df_residuos_nf, verbose=False)\n",
    "                preds_residuos_log = nf_residuos.predict()['NBEATS'].values\n",
    "                previsoes_teste['Híbrido (MIMO)'] = previsoes_teste['ARIMA'] + preds_residuos_log\n",
    "            except Exception as e: print(f\"AVISO: Híbrido (MIMO) falhou: {e}\")\n",
    "            \n",
    "        df_final = pd.DataFrame(previsoes_teste, index=teste_orig.index)\n",
    "        df_final['dataset'] = nome_da_serie\n",
    "        df_final['horizonte'] = horizonte\n",
    "        return df_final.reset_index().rename(columns={'index': 'ds'})\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERRO GERAL no processamento de '{nome_da_serie}' para o horizonte {horizonte}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a005504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 6: ORQUESTRADOR\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df8e17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Datasets:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando dados de 'AirPassengers' via statsmodels...\n",
      "-> Cópia do dataset 'AirPassengers' salva em: ./data/bronze\\airpassengers.csv\n",
      "Processando: ARIMA para horizonte 12\n",
      "Buscando melhor ordem ARIMA com auto_arima...\n",
      "Melhor ordem encontrada: (2, 0, 0) Sazonal: (0, 1, 1, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando: N-BEATS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.4 M  | train\n",
      "-------------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "900       Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.789     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s, v_num=1869, train_loss_step=0.0372, train_loss_epoch=0.0372]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s, v_num=1869, train_loss_step=0.0372, train_loss_epoch=0.0372]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.50it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | mlp          | ModuleList    | 1.1 M  | train\n",
      "4 | out          | Linear        | 12.3 K | train\n",
      "-------------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.350     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=1871, train_loss_step=0.0705, train_loss_epoch=0.0705]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=1871, train_loss_step=0.0705, train_loss_epoch=0.0705]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type          | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | loss            | MAE           | 0      | train\n",
      "1 | padder          | ConstantPad1d | 0      | train\n",
      "2 | scaler          | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "4 | context_adapter | Linear        | 24.1 K | train\n",
      "5 | mlp_decoder     | MLP           | 2.4 K  | train\n",
      "----------------------------------------------------------\n",
      "510 K     Trainable params\n",
      "0         Non-trainable params\n",
      "510 K     Total params\n",
      "2.042     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 26.08it/s, v_num=1873, train_loss_step=0.331, train_loss_epoch=0.331]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 21.82it/s, v_num=1873, train_loss_step=0.331, train_loss_epoch=0.331]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 39.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: Autoformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | decomp        | SeriesDecomp  | 0      | train\n",
      "4 | enc_embedding | DataEmbedding | 384    | train\n",
      "5 | dec_embedding | DataEmbedding | 384    | train\n",
      "6 | encoder       | Encoder       | 148 K  | train\n",
      "7 | decoder       | Decoder       | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "290 K     Trainable params\n",
      "0         Non-trainable params\n",
      "290 K     Total params\n",
      "1.162     Total estimated model params size (MB)\n",
      "85        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=1875, train_loss_step=0.390, train_loss_epoch=0.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=1875, train_loss_step=0.390, train_loss_epoch=0.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 20.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: NHITS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.4 M  | train\n",
      "-------------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.751     Total estimated model params size (MB)\n",
      "34        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s, v_num=1877, train_loss_step=0.0618, train_loss_epoch=0.0618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  4.25it/s, v_num=1877, train_loss_step=0.0618, train_loss_epoch=0.0618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 48.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: Híbrido (MIMO)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.4 M  | train\n",
      "-------------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "900       Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.789     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s, v_num=1879, train_loss_step=0.0121, train_loss_epoch=0.0121]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s, v_num=1879, train_loss_step=0.0121, train_loss_epoch=0.0121]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.32it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Buscando dados de 'AirPassengers' via statsmodels...\n",
      "-> Cópia do dataset 'AirPassengers' salva em: ./data/bronze\\airpassengers.csv\n",
      "Processando: ARIMA para horizonte 24\n",
      "Buscando melhor ordem ARIMA com auto_arima...\n",
      "Melhor ordem encontrada: (2, 0, 0) Sazonal: (0, 1, 1, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.5 M  | train\n",
      "-------------------------------------------------------\n",
      "2.5 M     Trainable params\n",
      "3.5 K     Non-trainable params\n",
      "2.5 M     Total params\n",
      "10.120    Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando: N-BEATS\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  3.62it/s, v_num=1881, train_loss_step=0.0168, train_loss_epoch=0.0168]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s, v_num=1881, train_loss_step=0.0168, train_loss_epoch=0.0168]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.59it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | mlp          | ModuleList    | 1.1 M  | train\n",
      "4 | out          | Linear        | 24.6 K | train\n",
      "-------------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.498     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=1883, train_loss_step=0.0511, train_loss_epoch=0.0511]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=1883, train_loss_step=0.0511, train_loss_epoch=0.0511]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.49it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type          | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | loss            | MAE           | 0      | train\n",
      "1 | padder          | ConstantPad1d | 0      | train\n",
      "2 | scaler          | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "4 | context_adapter | Linear        | 48.2 K | train\n",
      "5 | mlp_decoder     | MLP           | 2.4 K  | train\n",
      "----------------------------------------------------------\n",
      "534 K     Trainable params\n",
      "0         Non-trainable params\n",
      "534 K     Total params\n",
      "2.139     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 21.04it/s, v_num=1885, train_loss_step=0.287, train_loss_epoch=0.287]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 17.81it/s, v_num=1885, train_loss_step=0.287, train_loss_epoch=0.287]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: Autoformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | decomp        | SeriesDecomp  | 0      | train\n",
      "4 | enc_embedding | DataEmbedding | 384    | train\n",
      "5 | dec_embedding | DataEmbedding | 384    | train\n",
      "6 | encoder       | Encoder       | 148 K  | train\n",
      "7 | decoder       | Decoder       | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "290 K     Trainable params\n",
      "0         Non-trainable params\n",
      "290 K     Total params\n",
      "1.162     Total estimated model params size (MB)\n",
      "85        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:08<00:00,  0.11it/s, v_num=1887, train_loss_step=0.327, train_loss_epoch=0.327]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:08<00:00,  0.11it/s, v_num=1887, train_loss_step=0.327, train_loss_epoch=0.327]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: NHITS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.5 M  | train\n",
      "-------------------------------------------------------\n",
      "2.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 M     Total params\n",
      "10.040    Total estimated model params size (MB)\n",
      "34        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s, v_num=1889, train_loss_step=0.0312, train_loss_epoch=0.0312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s, v_num=1889, train_loss_step=0.0312, train_loss_epoch=0.0312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 87.05it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: Híbrido (MIMO)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.5 M  | train\n",
      "-------------------------------------------------------\n",
      "2.5 M     Trainable params\n",
      "3.5 K     Non-trainable params\n",
      "2.5 M     Total params\n",
      "10.120    Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  2.64it/s, v_num=1891, train_loss_step=0.00859, train_loss_epoch=0.00859]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  2.56it/s, v_num=1891, train_loss_step=0.00859, train_loss_epoch=0.00859]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Datasets:  50%|█████     | 1/2 [41:03<41:03, 2463.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando dados de 'co2' via statsmodels...\n",
      "-> Cópia do dataset 'co2' salva em: ./data/bronze\\co2.csv\n",
      "Processando: ARIMA para horizonte 12\n",
      "Buscando melhor ordem ARIMA com auto_arima...\n",
      "Melhor ordem encontrada: (3, 1, 2) Sazonal: (2, 0, 2, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando: N-BEATS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.4 M  | train\n",
      "-------------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "900       Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.789     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  4.14it/s, v_num=1893, train_loss_step=0.137, train_loss_epoch=0.137]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s, v_num=1893, train_loss_step=0.137, train_loss_epoch=0.137]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | mlp          | ModuleList    | 1.1 M  | train\n",
      "4 | out          | Linear        | 12.3 K | train\n",
      "-------------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.350     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=1895, train_loss_step=0.138, train_loss_epoch=0.138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=1895, train_loss_step=0.138, train_loss_epoch=0.138]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 46.10it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type          | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | loss            | MAE           | 0      | train\n",
      "1 | padder          | ConstantPad1d | 0      | train\n",
      "2 | scaler          | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "4 | context_adapter | Linear        | 24.1 K | train\n",
      "5 | mlp_decoder     | MLP           | 2.4 K  | train\n",
      "----------------------------------------------------------\n",
      "510 K     Trainable params\n",
      "0         Non-trainable params\n",
      "510 K     Total params\n",
      "2.042     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 22.95it/s, v_num=1897, train_loss_step=0.198, train_loss_epoch=0.198]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 20.39it/s, v_num=1897, train_loss_step=0.198, train_loss_epoch=0.198]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: Autoformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | decomp        | SeriesDecomp  | 0      | train\n",
      "4 | enc_embedding | DataEmbedding | 384    | train\n",
      "5 | dec_embedding | DataEmbedding | 384    | train\n",
      "6 | encoder       | Encoder       | 148 K  | train\n",
      "7 | decoder       | Decoder       | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "290 K     Trainable params\n",
      "0         Non-trainable params\n",
      "290 K     Total params\n",
      "1.162     Total estimated model params size (MB)\n",
      "85        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:04<00:00,  0.24it/s, v_num=1899, train_loss_step=0.273, train_loss_epoch=0.273]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:04<00:00,  0.23it/s, v_num=1899, train_loss_step=0.273, train_loss_epoch=0.273]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 31.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: NHITS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.4 M  | train\n",
      "-------------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.751     Total estimated model params size (MB)\n",
      "34        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s, v_num=1901, train_loss_step=0.149, train_loss_epoch=0.149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s, v_num=1901, train_loss_step=0.149, train_loss_epoch=0.149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: Híbrido (MIMO)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.4 M  | train\n",
      "-------------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "900       Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.789     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s, v_num=1903, train_loss_step=0.0439, train_loss_epoch=0.0439]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  3.61it/s, v_num=1903, train_loss_step=0.0439, train_loss_epoch=0.0439]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 73.06it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Buscando dados de 'co2' via statsmodels...\n",
      "-> Cópia do dataset 'co2' salva em: ./data/bronze\\co2.csv\n",
      "Processando: ARIMA para horizonte 24\n",
      "Buscando melhor ordem ARIMA com auto_arima...\n",
      "Melhor ordem encontrada: (3, 1, 1) Sazonal: (2, 0, 2, 12)\n"
     ]
    }
   ],
   "source": [
    "LISTA_DE_DATASETS = ['AirPassengers', 'co2'] \n",
    "VETOR_DE_HORIZONTES = [12, 24]\n",
    "resultados_gerais = []\n",
    "output_dir = \"./data/silver\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, \"resultados_completos.csv\")\n",
    "\n",
    "for dataset in tqdm(LISTA_DE_DATASETS, desc=\"Processando Datasets\"):\n",
    "    for horizonte in tqdm(VETOR_DE_HORIZONTES, desc=f\"Testando Horizontes para {dataset}\", leave=False):\n",
    "        df_resultado_detalhado = executar_experimento(dataset, horizonte)\n",
    "        if df_resultado_detalhado is not None:\n",
    "            resultados_gerais.append(df_resultado_detalhado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c51cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if resultados_gerais:\n",
    "    df_final = pd.concat(resultados_gerais)\n",
    "    df_final.to_csv(output_file, index=False)\n",
    "    print(f\"\\nArquivo '{output_file}' salvo com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e21be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 7: GERAÇÃO DE RELATÓRIOS A PARTIR DOS ARQUIVOS SALVOS\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a1d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\" + \"=\"*60); print(\"     GERANDO SUÍTE COMPLETA DE RELATÓRIOS\"); print(\"=\"*60)\n",
    "try:\n",
    "    df_results = pd.read_csv(output_file)\n",
    "    modelos = [col for col in df_results.columns if col not in ['ds', 'y_true', 'dataset', 'horizonte']]\n",
    "    \n",
    "    # 1. Cálculo das Métricas a partir dos resultados brutos\n",
    "    y_train_dict = {dataset: dividir_serie_temporal(carregar_serie(dataset))[0].values for dataset in df_results['dataset'].unique()}\n",
    "    df_melted = df_results.melt(id_vars=['ds', 'y_true', 'dataset', 'horizonte'], value_vars=modelos, var_name='Modelo', value_name='y_pred')\n",
    "    \n",
    "    metricas_gerais = []\n",
    "    for (dataset, horizonte, modelo), group in df_melted.groupby(['dataset', 'horizonte', 'Modelo']):\n",
    "        if not group['y_pred'].isnull().all():\n",
    "            metricas = calcular_metricas(group['y_true'], group['y_pred'], y_train_dict[dataset])\n",
    "            metricas['dataset'], metricas['horizonte'], metricas['Modelo'] = dataset, horizonte, modelo\n",
    "            metricas_gerais.append(metricas)\n",
    "    \n",
    "    df_metricas_final = pd.DataFrame(metricas_gerais)\n",
    "    rename_dict = {'RMSE': 'Mean RMSE', 'MAPE(%)': 'Mean MAPE(%)', 'MASE': 'Mean MASE'}\n",
    "    df_metricas_final.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "    # --- Relatório 1: Evolução do Erro por Horizonte ---\n",
    "    print(\"\\n--- RELATÓRIO 1: EVOLUÇÃO DO ERRO (RMSE) POR HORIZONTE ---\")\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.lineplot(data=df_metricas_final, x='horizonte', y='Mean RMSE', hue='Modelo', style='Modelo', markers=True, dashes=False)\n",
    "    plt.title(\"Evolução do Erro (RMSE) com o Aumento do Horizonte\", fontsize=16)\n",
    "    plt.xlabel(\"Horizonte de Previsão\"), plt.ylabel(\"RMSE Médio\"), plt.grid(True)\n",
    "    plt.xticks(df_metricas_final['horizonte'].unique()), plt.legend(title='Modelo'), plt.show()\n",
    "\n",
    "    # --- Relatório 2: Desempenho Detalhado (foco no maior horizonte) ---\n",
    "    print(\"\\n--- RELATÓRIO 2: DESEMPENHO DETALHADO (HORIZONTE MAIS LONGO) ---\")\n",
    "    maior_horizonte = df_metricas_final['horizonte'].max()\n",
    "    display(Markdown(f\"A tabela a seguir mostra o desempenho detalhado para o horizonte mais longo testado: **{maior_horizonte} passos**.\"))\n",
    "    df_detalhado = df_metricas_final[df_metricas_final['horizonte'] == maior_horizonte].set_index(['dataset', 'Modelo']).drop(columns=['horizonte'])\n",
    "    display(df_detalhado.style.format('{:.3f}'))\n",
    "    \n",
    "    # --- Relatório 3: Ranking dos Modelos (foco no maior horizonte) ---\n",
    "    print(\"\\n--- RELATÓRIO 3: RANKING DOS MODELOS (BASEADO EM RMSE, HORIZONTE MAIS LONGO) ---\")\n",
    "    df_rank = df_metricas_final[df_metricas_final['horizonte'] == maior_horizonte]\n",
    "    df_rank['Rank'] = df_rank.groupby('dataset')['Mean RMSE'].rank().astype(int)\n",
    "    df_pivot_rank = df_rank.pivot_table(index='dataset', columns='Modelo', values='Rank')\n",
    "    if len(df_pivot_rank) > 1: df_pivot_rank.loc['Média do Rank'] = df_pivot_rank.mean(axis=0)\n",
    "    display(df_pivot_rank.style.format('{:.1f}').highlight_min(axis=1, props='background-color: #4285F4; color: white;'))\n",
    "\n",
    "    # --- Relatório 4: Teste de Hipótese Diebold-Mariano (foco no maior horizonte) ---\n",
    "    print(\"\\n--- RELATÓRIO 4: TESTE DE HIPÓTESE DIEBOLD-MARIANO (p-valor, HORIZONTE MAIS LONGO) ---\")\n",
    "    modelo_referencia = 'Híbrido (MIMO)'\n",
    "    df_teste_maior_h = df_results[df_results['horizonte'] == maior_horizonte]\n",
    "    dm_results = []\n",
    "    for dataset_nome, group in df_teste_maior_h.groupby('dataset'):\n",
    "        if modelo_referencia in group.columns and not group[modelo_referencia].isnull().all():\n",
    "            row = {'dataset': dataset_nome}\n",
    "            erros_ref = group['y_true'] - group[modelo_referencia]\n",
    "            for modelo_comp in [m for m in modelos if m != modelo_referencia and m in group.columns and not group[m].isnull().all()]:\n",
    "                erros_comp = group['y_true'] - group[modelo_comp]\n",
    "                try:\n",
    "                    _, p_value = dm_test(erros_ref, erros_comp, alternative='less')\n",
    "                    row[modelo_comp] = p_value\n",
    "                except: row[modelo_comp] = np.nan\n",
    "            dm_results.append(row)\n",
    "    if dm_results:\n",
    "        df_dm = pd.DataFrame(dm_results).set_index('dataset')\n",
    "        display(df_dm.style.format('{:.3f}').applymap(lambda x: 'background-color: lightgreen' if pd.notna(x) and x < 0.05 else ''))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nERRO: Arquivo '{output_file}' não encontrado.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro ao gerar os relatórios: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybrid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
