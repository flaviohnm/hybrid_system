{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c96030f3be3e4a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T00:52:59.360703Z",
     "start_time": "2025-06-19T00:52:59.356446Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 1: IMPORTAÇÕES E SETUP GERAL\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9716172789275c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T00:52:59.414429Z",
     "start_time": "2025-06-19T00:52:59.376419Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Libs de Modelagem e Estatística\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.datasets import get_rdataset\n",
    "from scipy.stats import friedmanchisquare\n",
    "import pmdarima as pm\n",
    "import scikit_posthocs as sp\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS, MLP, LSTM, Autoformer, NHITS\n",
    "\n",
    "# Libs de Avaliação\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acde5f0e5c4b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 2: FUNÇÕES AUXILIARES (SETUP E PROCESSAMENTO)\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff04ae19676ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def definir_seed(seed_value=42):\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68444ac84157ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_serie(nome, pasta_cache=\"./data/bronze\"):\n",
    "\n",
    "    nome_base = nome.lower()\n",
    "    # Garante que o diretório de cache exista\n",
    "    os.makedirs(pasta_cache, exist_ok=True)\n",
    "    caminho_arquivo = os.path.join(pasta_cache, f\"{nome_base}.csv\")\n",
    "\n",
    "    # Passo 1: Verifica se o arquivo já existe localmente\n",
    "    if os.path.exists(caminho_arquivo):\n",
    "        print(f\"Carregando dataset '{nome}' do cache local: {caminho_arquivo}\")\n",
    "        # Se existir, carrega diretamente do CSV, garantindo que a data seja o índice\n",
    "        df = pd.read_csv(caminho_arquivo, parse_dates=['date'], index_col='date')\n",
    "        # Retorna a série com o nome original para consistência\n",
    "        df['value'].name = nome\n",
    "        return df['value']\n",
    "\n",
    "    # Passo 2: Se não existir, faz o download\n",
    "    print(f\"Cache não encontrado. Buscando dados de '{nome}' via statsmodels...\")\n",
    "    \n",
    "    serie = None\n",
    "    if nome_base == \"airpassengers\":\n",
    "        dados = get_rdataset(\"AirPassengers\", package=\"datasets\").data\n",
    "        serie = pd.Series(dados['value'].values, index=pd.date_range(start=\"1949-01-01\", periods=len(dados), freq=\"MS\"), name=nome)\n",
    "    elif nome_base == \"lynx\":\n",
    "        dados = get_rdataset(\"lynx\", package=\"datasets\").data\n",
    "        serie = pd.Series(dados['value'].values, index=pd.date_range(start=\"1821\", periods=len(dados), freq=\"YE-DEC\"), name=nome)\n",
    "    elif nome_base == \"co2\":\n",
    "        dados = get_rdataset(\"CO2\", package=\"datasets\").data\n",
    "        dados = dados.ffill()\n",
    "        serie = pd.Series(dados['value'].values, index=pd.date_range(start=\"1958-03-29\", periods=len(dados), freq=\"MS\"), name=nome)\n",
    "    elif nome_base == \"austres\":\n",
    "        dados = get_rdataset(\"austres\", package=\"datasets\").data\n",
    "        serie = pd.Series(dados['value'].values, index=pd.date_range(start=\"1971-03-01\", periods=len(dados), freq=\"QS-MAR\"), name=nome)\n",
    "    elif nome_base == \"nottem\":\n",
    "        dados = get_rdataset(\"nottem\", package=\"datasets\").data\n",
    "        serie = pd.Series(dados['value'].values, index=pd.date_range(start=\"1920-01-01\", periods=len(dados), freq=\"MS\"), name=nome)\n",
    "    else:\n",
    "        raise ValueError(f\"Lógica de download para a série '{nome}' não implementada.\")\n",
    "\n",
    "    # Passo 3: Salva a série baixada no cache para uso futuro\n",
    "    if serie is not None:\n",
    "        print(f\"-> Salvando cópia do dataset '{nome}' em cache: {caminho_arquivo}\")\n",
    "        df_para_salvar = pd.DataFrame({\"date\": serie.index, \"value\": serie.values})\n",
    "        df_para_salvar.to_csv(caminho_arquivo, index=False)\n",
    "    \n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a220cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_serie_temporal(serie, percentual_treino=0.85):\n",
    "    tamanho_total = len(serie)\n",
    "    ponto_corte_treino = int(tamanho_total * percentual_treino)\n",
    "    treino = serie.iloc[:ponto_corte_treino]\n",
    "    teste = serie.iloc[ponto_corte_treino:]\n",
    "    return treino, teste\n",
    "\n",
    "def preparar_dados_para_neuralforecast(serie, nome_serie):\n",
    "    df = serie.reset_index()\n",
    "    df.columns = ['ds', 'y']\n",
    "    df['unique_id'] = nome_serie\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767138d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 3: FUNÇÕES PARA CÁLCULO DE MÉTRICAS E MODELAGEM\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38b31116385f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas(y_true, y_pred, y_train):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100 if np.all(y_true != 0) else np.inf\n",
    "    n = len(y_train)\n",
    "    d = np.sum(np.abs(y_train[1:] - y_train[:-1])) / (n - 1) if n > 1 else np.nan\n",
    "    mase = np.mean(np.abs(y_true - y_pred)) / d if d is not np.nan and d > 0 else np.inf\n",
    "    return {'RMSE': rmse, 'MAPE(%)': mape, 'MASE': mase}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae6b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 4: PIPELINE AVANÇADO PARA O ARIMA\n",
    "# =========================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc9d2b54e19eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_melhor_arima_auto(treino_log, freq):\n",
    "    \"\"\"Usa auto_arima para encontrar a melhor ordem ARIMA, incluindo sazonalidade.\"\"\"\n",
    "    print(\"Buscando melhor ordem ARIMA com auto_arima...\")\n",
    "    m = 12 if freq.startswith('M') else (4 if freq.startswith('Q') else 1)\n",
    "    auto_arima_model = pm.auto_arima(treino_log, m=m, seasonal=True, trace=False, error_action='ignore', suppress_warnings=True, stepwise=True)\n",
    "    print(f\"Melhor ordem encontrada: {auto_arima_model.order} Sazonal: {auto_arima_model.seasonal_order}\")\n",
    "    return auto_arima_model.order, auto_arima_model.seasonal_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189a54af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 5: PIPELINE DE EXPERIMENTO COMPLETO E AVANÇADO\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c9b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executar_experimento(nome_da_serie, horizonte):\n",
    "    \"\"\"Executa o pipeline completo, agora incluindo o Híbrido Recursive-Direct do artigo.\"\"\"\n",
    "    try:\n",
    "        SEED = 42\n",
    "        definir_seed(SEED)\n",
    "        MAX_INPUT_SIZE = 24\n",
    "        MAX_STEPS_NEURAL = 150\n",
    "        \n",
    "        serie_original = carregar_serie(nome_da_serie)\n",
    "        \n",
    "        percentual_treino = 1 - (horizonte / len(serie_original))\n",
    "        if percentual_treino < 0.5:\n",
    "             print(f\"AVISO: Horizonte {horizonte} é muito grande para a série '{nome_da_serie}'. Pulando.\")\n",
    "             return None\n",
    "        \n",
    "        treino_orig, teste_orig = dividir_serie_temporal(serie_original, percentual_treino=percentual_treino)\n",
    "        serie_log = np.log(serie_original)\n",
    "        treino_log, _ = dividir_serie_temporal(serie_log, percentual_treino=percentual_treino)\n",
    "        \n",
    "        freq = serie_original.index.freqstr or pd.infer_freq(serie_original.index)\n",
    "        if freq is None: return None\n",
    "\n",
    "        previsoes_teste = {'y_true': teste_orig.values}\n",
    "        \n",
    "        # --- 1. Modelo ARIMA (Base para ambos os híbridos) ---\n",
    "        modelo_arima = None\n",
    "        try:\n",
    "            print(\"Processando: ARIMA\")\n",
    "            ordem, ordem_sazonal = encontrar_melhor_arima_auto(treino_log, freq)\n",
    "            modelo_arima = ARIMA(treino_log.asfreq(freq), order=ordem, seasonal_order=ordem_sazonal).fit()\n",
    "            preds_log_teste_arima = modelo_arima.forecast(steps=horizonte)\n",
    "            previsoes_teste['ARIMA'] = np.exp(preds_log_teste_arima).values\n",
    "        except Exception as e: \n",
    "            print(f\"AVISO: ARIMA falhou: {e}\")\n",
    "            return None # Retorna se o ARIMA falhar, pois é base para os híbridos\n",
    "\n",
    "        # --- 2. Modelos Neurais Puros ---\n",
    "        df_treino_log_nf = preparar_dados_para_neuralforecast(treino_log, nome_da_serie)\n",
    "        modelos_para_testar = {'N-BEATS': NBEATS, 'MLP': MLP, 'LSTM': LSTM, 'Autoformer': Autoformer, 'NHITS': NHITS}\n",
    "        \n",
    "        for nome_modelo, classe_modelo in modelos_para_testar.items():\n",
    "            try:\n",
    "                print(f\"Processando: {nome_modelo}\")\n",
    "                modelo_neural = [classe_modelo(input_size=min(2 * horizonte, MAX_INPUT_SIZE), h=horizonte, max_steps=MAX_STEPS_NEURAL, scaler_type='standard', random_seed=SEED)]\n",
    "                nf = NeuralForecast(models=modelo_neural, freq=freq)\n",
    "                nf.fit(df=df_treino_log_nf, verbose=False)\n",
    "                previsoes_teste[nome_modelo] = np.exp(nf.predict()[classe_modelo.__name__].values)\n",
    "            except Exception as e: print(f\"AVISO: {nome_modelo} falhou: {e}\")\n",
    "        \n",
    "        # Obter os resíduos do treino para os modelos híbridos\n",
    "        residuos_treino_log = modelo_arima.resid\n",
    "            \n",
    "        # --- 3. Modelo Híbrido (MIMO) - Sua implementação original ---\n",
    "        try:\n",
    "            print(\"Processando: Híbrido (MIMO)\")\n",
    "            df_residuos_nf = preparar_dados_para_neuralforecast(residuos_treino_log, \"residuos\")\n",
    "            # Treina um único modelo para prever todos os H passos\n",
    "            modelo_residuos_mimo = [NBEATS(input_size=min(2*horizonte, MAX_INPUT_SIZE), h=horizonte, max_steps=MAX_STEPS_NEURAL, scaler_type='standard', random_seed=SEED)]\n",
    "            nf_residuos_mimo = NeuralForecast(models=modelo_residuos_mimo, freq=freq)\n",
    "            nf_residuos_mimo.fit(df=df_residuos_nf, verbose=False)\n",
    "            preds_residuos_log_mimo = nf_residuos_mimo.predict()['NBEATS'].values\n",
    "            previsoes_teste['Híbrido (MIMO)'] = previsoes_teste['ARIMA'] + preds_residuos_log_mimo\n",
    "        except Exception as e: print(f\"AVISO: Híbrido (MIMO) falhou: {e}\")\n",
    "\n",
    "        # =========================================================================================\n",
    "        # --- 4. NOVO: Modelo Híbrido (Recursive-Direct) - Conforme o Artigo HyS-MF ---\n",
    "        # =========================================================================================\n",
    "        try:\n",
    "            print(\"Processando: Híbrido (Recursive-Direct)\")\n",
    "            preds_residuos_log_direct = []\n",
    "            \n",
    "            # Loop para treinar um modelo especialista para cada passo do horizonte\n",
    "            for h_step in range(1, horizonte + 1):\n",
    "                print(f\"  -> Treinando especialista para horizonte h={h_step}\")\n",
    "                \n",
    "                # Prepara os dados para a abordagem Direct: o alvo 'y' é o resíduo h_step passos no futuro\n",
    "                df_residuos_h = residuos_treino_log.to_frame(name='y')\n",
    "                df_residuos_h['ds'] = df_residuos_h.index\n",
    "                df_residuos_h['y'] = df_residuos_h['y'].shift(-h_step + 1) # Desloca o alvo\n",
    "                df_residuos_h.dropna(inplace=True) # Remove os NaNs criados pelo shift\n",
    "                df_residuos_h['unique_id'] = f\"residuos_h{h_step}\"\n",
    "\n",
    "                # Treina um modelo N-BEATS para prever apenas 1 passo à frente (o seu alvo específico)\n",
    "                modelo_residuos_direct = [NBEATS(input_size=min(2*horizonte, MAX_INPUT_SIZE), h=1, max_steps=MAX_STEPS_NEURAL, scaler_type='standard', random_seed=SEED)]\n",
    "                nf_residuos_direct = NeuralForecast(models=modelo_residuos_direct, freq=freq)\n",
    "                nf_residuos_direct.fit(df=df_residuos_h, verbose=False)\n",
    "                \n",
    "                # Faz a previsão de 1 passo (que corresponde ao h_step do resíduo)\n",
    "                pred_h = nf_residuos_direct.predict()['NBEATS'].values[0]\n",
    "                preds_residuos_log_direct.append(pred_h)\n",
    "\n",
    "            # Combina a previsão do ARIMA com a soma das previsões dos resíduos\n",
    "            previsoes_teste['Híbrido (Recursive-Direct)'] = previsoes_teste['ARIMA'] + np.array(preds_residuos_log_direct)\n",
    "        except Exception as e: \n",
    "            print(f\"AVISO: Híbrido (Recursive-Direct) falhou: {e}\")\n",
    "\n",
    "        df_final = pd.DataFrame(previsoes_teste, index=teste_orig.index)\n",
    "        df_final['dataset'] = nome_da_serie\n",
    "        df_final['horizonte'] = horizonte\n",
    "        return df_final.reset_index().rename(columns={'index': 'ds'})\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ERRO GERAL no processamento de '{nome_da_serie}' para o horizonte {horizonte}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98690e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 6: ORQUESTRADOR (LÓGICA DA CAMADA SILVER)\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861667f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configurações ---\n",
    "LISTA_DE_DATASETS = ['AirPassengers', 'co2', 'nottem', 'austres', 'lynx']\n",
    "VETOR_DE_HORIZONTES = [10, 12, 15, 24]\n",
    "output_dir = \"./data/silver\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, \"resultados_completos.csv\")\n",
    "\n",
    "# --- Lógica de Execução Incremental ---\n",
    "# Apaga o arquivo antigo para garantir uma execução limpa\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "header_escrito = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ec1cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in tqdm(LISTA_DE_DATASETS, desc=\"Processando Datasets\"):\n",
    "    for horizonte in tqdm(VETOR_DE_HORIZONTES, desc=f\"Testando Horizontes para {dataset}\", leave=False):\n",
    "        # Executa o experimento para uma combinação de dataset e horizonte\n",
    "        df_resultado_detalhado = executar_experimento(dataset, horizonte)\n",
    "        \n",
    "        if df_resultado_detalhado is not None:\n",
    "            # Lógica para salvar incrementalmente no arquivo da camada Silver\n",
    "            if not header_escrito:\n",
    "                # Escreve o cabeçalho apenas na primeira vez\n",
    "                df_resultado_detalhado.to_csv(output_file, index=False, mode='w', header=True)\n",
    "                header_escrito = True\n",
    "            else:\n",
    "                # Anexa os novos resultados sem o cabeçalho\n",
    "                df_resultado_detalhado.to_csv(output_file, index=False, mode='a', header=False)\n",
    "\n",
    "print(f\"\\nProcesso finalizado. Resultados salvos em '{output_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a005504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 6: ORQUESTRADOR\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9f10c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LISTA_DE_DATASETS = ['AirPassengers', 'co2', 'nottem', 'austres', 'lynx'] \n",
    "VETOR_DE_HORIZONTES = [10, 12, 15, 24]\n",
    "resultados_gerais = []\n",
    "output_dir = \"./data/silver\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, \"resultados_completos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df8e17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in tqdm(LISTA_DE_DATASETS, desc=\"Processando Datasets\"):\n",
    "    for horizonte in tqdm(VETOR_DE_HORIZONTES, desc=f\"Testando Horizontes para {dataset}\", leave=False):\n",
    "        df_resultado_detalhado = executar_experimento(dataset, horizonte)\n",
    "        if df_resultado_detalhado is not None:\n",
    "            resultados_gerais.append(df_resultado_detalhado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c51cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if resultados_gerais:\n",
    "    df_final = pd.concat(resultados_gerais)\n",
    "    df_final.to_csv(output_file, index=False)\n",
    "    print(f\"\\nArquivo '{output_file}' salvo com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e21be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# SEÇÃO 7: GERAÇÃO DE RELATÓRIOS (ARQUITETURA MODULAR)\n",
    "# ================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9da750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas_finais(df_results):\n",
    "    \"\"\"\n",
    "    Função auxiliar robusta para calcular as métricas a partir do DataFrame de previsões brutas.\n",
    "    \"\"\"\n",
    "    modelos = [col for col in df_results.columns if col not in ['ds', 'y_true', 'dataset', 'horizonte']]\n",
    "    \n",
    "    # Dicionário para armazenar dados de treino para o cálculo do MASE\n",
    "    y_train_dict = {}\n",
    "    \n",
    "    # Para cada dataset, carrega os dados de treino e teste originais para o cálculo do MASE\n",
    "    for dataset_nome in df_results['dataset'].unique():\n",
    "        horizonte_max_ds = df_results[df_results['dataset'] == dataset_nome]['horizonte'].max()\n",
    "        serie_original = carregar_serie(dataset_nome)\n",
    "        percentual_treino = 1 - (horizonte_max_ds / len(serie_original))\n",
    "        treino, _ = dividir_serie_temporal(serie_original, percentual_treino)\n",
    "        y_train_dict[dataset_nome] = treino.values\n",
    "\n",
    "    # Transforma o DataFrame de 'largo' para 'longo' para facilitar a agregação\n",
    "    df_melted = df_results.melt(id_vars=['ds', 'y_true', 'dataset', 'horizonte'], \n",
    "                                value_vars=modelos, var_name='Modelo', value_name='y_pred')\n",
    "    \n",
    "    metricas_gerais = []\n",
    "    # Agrupa para calcular as métricas para cada combinação de dataset, horizonte e modelo\n",
    "    for (dataset, horizonte, modelo), group in tqdm(df_melted.groupby(['dataset', 'horizonte', 'Modelo']), desc=\"Calculando Métricas\"):\n",
    "        if not group['y_pred'].isnull().all():\n",
    "            # Passa a fatia correta dos dados de treino para o MASE\n",
    "            y_train_correto = y_train_dict[dataset]\n",
    "            \n",
    "            # Calcula as métricas\n",
    "            metricas_dict = calcular_metricas(group['y_true'], group['y_pred'], y_train_correto)\n",
    "            \n",
    "            # Adiciona as informações de metadados ao dicionário\n",
    "            metricas_dict['dataset'] = dataset\n",
    "            metricas_dict['horizonte'] = horizonte\n",
    "            metricas_dict['Modelo'] = modelo\n",
    "            \n",
    "            metricas_gerais.append(metricas_dict)\n",
    "    \n",
    "    df_metricas_final = pd.DataFrame(metricas_gerais)\n",
    "    # Renomeia colunas para clareza nos relatórios\n",
    "    df_metricas_final.rename(columns={'RMSE': 'Mean RMSE', 'MAPE(%)': 'Mean MAPE(%)', 'MASE': 'Mean MASE'}, inplace=True)\n",
    "    return df_metricas_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea16328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotar_evolucao_erro(df_metricas, vetor_horizontes):\n",
    "    \"\"\"RELATÓRIO 1: Gera o gráfico de linha da evolução do erro.\"\"\"\n",
    "    print(\"\\n--- RELATÓRIO 1: EVOLUÇÃO DO ERRO (RMSE) POR HORIZONTE ---\")\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.lineplot(data=df_metricas, x='horizonte', y='Mean RMSE', hue='Modelo', style='Modelo', markers=True, dashes=False)\n",
    "    plt.title(\"Evolução do Erro (RMSE) com o Aumento do Horizonte\", fontsize=16)\n",
    "    plt.xlabel(\"Horizonte de Previsão\"); plt.ylabel(\"RMSE Médio\"); plt.grid(True)\n",
    "    if not df_metricas.empty:\n",
    "        plt.xticks(vetor_horizontes)\n",
    "    plt.legend(title='Modelo'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41407c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exibir_desempenho_agregado(df_foco):\n",
    "    \"\"\"RELATÓRIO 2: Mostra a tabela de desempenho geral agregado.\"\"\"\n",
    "    print(\"\\n--- RELATÓRIO 2: DESEMPENHO GERAL (MÉDIA NO HORIZONTE MAIS LONGO) ---\")\n",
    "    df_agrupado = df_foco.groupby('Modelo')[['Mean RMSE', 'Mean MAPE(%)', 'Mean MASE']].mean()\n",
    "    display(df_agrupado.style.format('{:.3f}').highlight_min(axis=0, props='background-color: #4285F4; color: white;'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83639f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exibir_desempenho_detalhado(df_foco):\n",
    "    \"\"\"RELATÓRIO 3: Mostra a tabela de desempenho detalhado por dataset.\"\"\"\n",
    "    print(\"\\n--- RELATÓRIO 3: DESEMPENHO DETALHADO POR DATASET (HORIZONTE MAIS LONGO) ---\")\n",
    "    df_reporte_detalhado = df_foco.set_index(['dataset', 'Modelo']).drop(columns=['horizonte'])\n",
    "    display(df_reporte_detalhado.style.format('{:.3f}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717c80e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exibir_tabela_ranking(df_foco):\n",
    "    \"\"\"RELATÓRIO 4: Mostra a tabela de ranking e a retorna para uso posterior.\"\"\"\n",
    "    print(\"\\n--- RELATÓRIO 4: RANKING DOS MODELOS (BASEADO EM RMSE, HORIZONTE MAIS LONGO) ---\")\n",
    "    df_rank = df_foco.copy()\n",
    "    df_rank['Rank'] = df_rank.groupby('dataset')['Mean RMSE'].rank().astype(int)\n",
    "    df_pivot_rank = df_rank.pivot_table(index='dataset', columns='Modelo', values='Rank')\n",
    "    if len(df_pivot_rank) > 1:\n",
    "        df_pivot_rank.loc['Média do Rank'] = df_pivot_rank.mean(axis=0)\n",
    "    display(df_pivot_rank.style.format('{:.1f}').highlight_min(axis=1, props='background-color: #4285F4; color: white;'))\n",
    "    return df_pivot_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15059a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotar_diferenca_percentual(df_foco):\n",
    "    \"\"\"RELATÓRIO 5: Mostra o gráfico de ganho percentual do modelo híbrido.\"\"\"\n",
    "    print(\"\\n--- RELATÓRIO 5: GANHO PERCENTUAL DO MODELO HÍBRIDO (BASEADO EM MAPE, HORIZONTE MAIS LONGO) ---\")\n",
    "    df_pivot_mape = df_foco.pivot_table(index='dataset', columns='Modelo', values='Mean MAPE(%)')\n",
    "    modelo_referencia_hibrido = 'Híbrido (MIMO)'\n",
    "    if modelo_referencia_hibrido in df_pivot_mape.columns:\n",
    "        mape_hibrido = df_pivot_mape[modelo_referencia_hibrido]\n",
    "        df_pd = pd.DataFrame(index=df_pivot_mape.index)\n",
    "        for modelo in [m for m in df_pivot_mape.columns if m != modelo_referencia_hibrido]:\n",
    "            df_pd[f'Ganho sobre {modelo} (%)'] = 100 * (df_pivot_mape[modelo] - mape_hibrido) / df_pivot_mape[modelo]\n",
    "        ax = df_pd.plot(kind='bar', figsize=(14, 7), grid=True, rot=45); ax.set_ylabel(\"Melhora Percentual (%)\"); ax.set_xlabel(\"Dataset\")\n",
    "        ax.set_title(f\"Diferença Percentual (PD%): Ganho de Performance do {modelo_referencia_hibrido}\"); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c429b8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exibir_analise_estatistica_demsar(df_pivot_rank, maior_horizonte):\n",
    "    \"\"\"RELATÓRIO 6: Executa e exibe os testes de Friedman e Nemenyi.\"\"\"\n",
    "    print(\"\\n\\n\" + \"=\"*60); print(f\"     RELATÓRIO 6: ANÁLISE ESTATÍSTICA GLOBAL (FRIEDMAN + NEMENYI, HORIZONTE {int(maior_horizonte)})\"); print(\"=\"*60)\n",
    "    \n",
    "    # --- CORREÇÃO APLICADA AQUI ---\n",
    "    # Inicializamos as variáveis como None para garantir que sempre existam.\n",
    "    p_values_nemenyi = None\n",
    "    avg_ranks = None\n",
    "    \n",
    "    df_rank_data = df_pivot_rank.drop('Média do Rank', errors='ignore')\n",
    "    if df_rank_data.empty:\n",
    "        print(\"AVISO: Tabela de ranking vazia, não foi possível executar a análise estatística.\")\n",
    "        # Retorna os valores nulos\n",
    "        return p_values_nemenyi, avg_ranks\n",
    "\n",
    "    try:\n",
    "        stat, p_value = friedmanchisquare(*[df_rank_data[col].values for col in df_rank_data.columns])\n",
    "        print(f\"\\n--- Teste de Friedman ---\\np-valor: {p_value:.4f}\")\n",
    "\n",
    "        if p_value < 0.05:\n",
    "            print(\"\\n**Conclusão: Há uma diferença estatisticamente significativa entre os modelos.**\")\n",
    "            \n",
    "            print(\"\\n--- Teste Post-hoc de Nemenyi (p-valores par a par) ---\")\n",
    "            df_rank_melted = df_rank_data.reset_index().melt(id_vars='dataset', var_name='Modelo', value_name='Rank')\n",
    "            p_values_nemenyi = sp.posthoc_nemenyi_friedman(df_rank_melted, melted=True, group_col='Modelo', block_col='dataset', y_col='Rank')\n",
    "            display(p_values_nemenyi.style.format('{:.3f}').applymap(lambda x: 'background-color: lightgreen' if x < 0.05 else ''))\n",
    "\n",
    "            # Calcula os ranks médios apenas se o teste for significativo\n",
    "            avg_ranks = df_pivot_rank.mean(axis=0).drop('Média do Rank', errors='ignore')\n",
    "        else:\n",
    "            print(\"\\n**Conclusão: Não há evidência de uma diferença estatística significativa entre os modelos.**\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"AVISO: A análise estatística avançada falhou: {e}\")\n",
    "        \n",
    "    # A função agora sempre retorna uma tupla, mesmo que os valores sejam None\n",
    "    return p_values_nemenyi, avg_ranks    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400ede50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotar_diagrama_diferenca_critica(df_pivot_rank, alpha=0.05):\n",
    "    \"\"\"RELATÓRIO ADICIONAL: Gera o Diagrama de Diferença Crítica (CD Plot).\"\"\"\n",
    "    if df_pivot_rank.empty:\n",
    "        print(\"AVISO: Tabela de ranking vazia, não é possível gerar o CD Plot.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\\\n--- DIAGRAMA DE DIFERENÇA CRÍTICA (CD PLOT) ---\")\n",
    "    display(Markdown(\"Este gráfico resume o teste de Nemenyi. Modelos que **NÃO** são significativamente diferentes estão conectados por uma linha horizontal.\"))\n",
    "    \n",
    "    # Extrai os dados de ranking e os nomes dos modelos\n",
    "    rank_data = df_pivot_rank.drop('Média do Rank', errors='ignore').values\n",
    "    model_names = df_pivot_rank.columns\n",
    "    \n",
    "    # Calcula a diferença crítica (CD)\n",
    "    # N = número de datasets, k = número de modelos\n",
    "    N = len(rank_data)\n",
    "    k = len(model_names)\n",
    "    \n",
    "    # Importa a tabela de valores críticos q_alpha do scikit-posthocs\n",
    "    from scikit_posthocs._critical_values import get_critical_value\n",
    "    q_alpha = get_critical_value(k, alpha)\n",
    "    \n",
    "    cd = q_alpha * np.sqrt(k * (k + 1) / (6 * N))\n",
    "    \n",
    "    # Calcula os ranks médios\n",
    "    avg_ranks = df_pivot_rank.loc['Média do Rank'].sort_values()\n",
    "    \n",
    "    # Gera o gráfico usando a função de plotagem do scikit-posthocs\n",
    "    sp.sign_plot(avg_ranks, cd=cd)\n",
    "    plt.title(f\"Diagrama de Diferença Crítica (Teste de Nemenyi, alpha={alpha})\", fontsize=16)\n",
    "    plt.xlabel(\"Ranking Médio\")\n",
    "    plt.show()\n",
    "\n",
    "# Na sua função principal de relatórios, a chamada seria:\n",
    "# df_pivot_rank = exibir_tabela_ranking(df_foco_maior_h)\n",
    "# plotar_diagrama_diferenca_critica(df_pivot_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb294a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NOVA FUNÇÃO DE RELATÓRIO (BASEADA NA TABELA 4 DO ARTIGO) ---\n",
    "def exibir_tabela_ranking(df_foco, metrica='Mean RMSE'):\n",
    "    \"\"\"RELATÓRIO 4: Mostra a tabela de ranking dos modelos.\"\"\"\n",
    "    print(f\"\\n--- RELATÓRIO 4: RANKING DOS MODELOS (BASEADO EM {metrica}) ---\")\n",
    "    df_rank = df_foco.copy()\n",
    "    rank_col_name = f'Rank_{metrica}'\n",
    "    df_rank[rank_col_name] = df_rank.groupby('dataset')[metrica].rank().astype(int)\n",
    "    df_pivot_rank = df_rank.pivot_table(index='dataset', columns='Modelo', values=rank_col_name)\n",
    "    if len(df_pivot_rank) > 1:\n",
    "        df_pivot_rank.loc['Média do Rank'] = df_pivot_rank.mean(axis=0)\n",
    "    display(df_pivot_rank.style.format('{:.1f}').highlight_min(axis=1, props='background-color: #4285F4; color: white;'))\n",
    "    return df_pivot_rank\n",
    "\n",
    "# --- NOVA FUNÇÃO DE RELATÓRIO (BASEADA NA TABELA 4 DO ARTIGO) ---\n",
    "def exibir_ranking_mape_artigo(df_foco):\n",
    "    \"\"\"RELATÓRIO EXTRA 1: Gera a tabela de ranking por MAPE, no estilo da Tabela 4 do artigo.\"\"\"\n",
    "    print(\"\\n\\n\" + \"=\"*60)\n",
    "    print(\"     RELATÓRIO ADICIONAL: TABELA DE RANKING POR MAPE (ESTILO ARTIGO)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    df_rank_mape = df_foco.copy()\n",
    "    df_rank_mape['Rank_MAPE'] = df_rank_mape.groupby('dataset')['Mean MAPE(%)'].rank().astype(int)\n",
    "    df_pivot = df_rank_mape.pivot_table(index='Modelo', columns='dataset', values='Rank_MAPE')\n",
    "    \n",
    "    # Calcula a Média e Mediana do Rank para cada modelo\n",
    "    df_pivot['Média'] = df_pivot.mean(axis=1)\n",
    "    df_pivot['Mediana'] = df_pivot.median(axis=1)\n",
    "    \n",
    "    def highlight_top3(s):\n",
    "        is_top3 = s <= 3\n",
    "        return ['background-color: blue' if v else '' for v in is_top3]\n",
    "\n",
    "    styled_pivot = (df_pivot.style\n",
    "                    .format('{:.1f}')\n",
    "                    .apply(highlight_top3, subset=pd.IndexSlice[:, [c for c in df_pivot.columns if c not in ['Média', 'Mediana']]])\n",
    "                    .set_caption(\"Ranking dos modelos por dataset baseado no MAPE (1 = Melhor).\"))\n",
    "    \n",
    "    display(styled_pivot)\n",
    "\n",
    "# --- NOVA FUNÇÃO DE RELATÓRIO (BASEADA NA FIGURA 9 DO ARTIGO) ---\n",
    "def plotar_pd_agregado(df_foco):\n",
    "    \"\"\"RELATÓRIO EXTRA 2: Gera o gráfico de Diferença Percentual (PD%) agregado.\"\"\"\n",
    "    print(\"\\n\\n\" + \"=\"*60)\n",
    "    print(\"     RELATÓRIO ADICIONAL: GRÁFICO DE DIFERENÇA PERCENTUAL AGREGADO (ESTILO FIGURA 9)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    modelo_referencia_hibrido = 'Híbrido (MIMO)'\n",
    "    # Calcula o MAPE médio para cada modelo, em todos os datasets\n",
    "    df_mean_mape = df_foco.groupby('Modelo')['Mean MAPE(%)'].mean()\n",
    "\n",
    "    if modelo_referencia_hibrido in df_mean_mape.index:\n",
    "        mape_hibrido = df_mean_mape[modelo_referencia_hibrido]\n",
    "        pd_values = []\n",
    "        for modelo, mape_medio in df_mean_mape.items():\n",
    "            if modelo != modelo_referencia_hibrido:\n",
    "                pd_value = 100 * (mape_medio - mape_hibrido) / mape_medio\n",
    "                pd_values.append({'Modelo': modelo, 'PD(%)': pd_value})\n",
    "        \n",
    "        if pd_values:\n",
    "            df_pd = pd.DataFrame(pd_values).sort_values(by='PD(%)')\n",
    "            \n",
    "            plt.figure(figsize=(14, 8))\n",
    "            ax = sns.barplot(x='Modelo', y='PD(%)', data=df_pd, palette='viridis', hue='Modelo', legend=False)\n",
    "            ax.set_title(f\"Diferença Percentual (PD%) Agregada do {modelo_referencia_hibrido}\", fontsize=16)\n",
    "            ax.set_ylabel(\"Melhora Percentual (%)\")\n",
    "            ax.set_xlabel(\"Modelo Competidor\")\n",
    "            plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af48c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NOVA FUNÇÃO DE RELATÓRIO ---\n",
    "def plotar_evolucao_ranking_mape(df_metricas, vetor_horizontes):\n",
    "    \"\"\"\n",
    "    RELATÓRIO NOVO: Gera o gráfico de linha da evolução do Ranking Médio por horizonte,\n",
    "    baseado no MAPE.\n",
    "    \"\"\"\n",
    "    print(\"\\n\\n\" + \"=\"*60)\n",
    "    print(\"     RELATÓRIO NOVO: EVOLUÇÃO DO RANKING MÉDIO (MAPE) POR HORIZONTE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Cria uma cópia para trabalhar com segurança\n",
    "    df_rank_mape = df_metricas.copy()\n",
    "    \n",
    "    # Calcula o ranking baseado em MAPE para cada dataset e horizonte\n",
    "    df_rank_mape['Rank_MAPE'] = df_rank_mape.groupby(['dataset', 'horizonte'])['Mean MAPE(%)'].rank().astype(int)\n",
    "    \n",
    "    # Calcula o rank médio para cada modelo em cada horizonte, através de todos os datasets\n",
    "    df_avg_rank = df_rank_mape.groupby(['horizonte', 'Modelo'])['Rank_MAPE'].mean().reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    ax = sns.lineplot(\n",
    "        data=df_avg_rank,\n",
    "        x='horizonte',\n",
    "        y='Rank_MAPE',\n",
    "        hue='Modelo',\n",
    "        style='Modelo',\n",
    "        markers=True,\n",
    "        dashes=False,\n",
    "        linewidth=2.5\n",
    "    )\n",
    "    ax.set_title(\"Evolução do Ranking Médio dos Modelos com o Aumento do Horizonte\", fontsize=16)\n",
    "    ax.set_xlabel(\"Horizonte de Previsão (Passos à Frente)\")\n",
    "    ax.set_ylabel(\"Ranking Médio (Menor é Melhor)\")\n",
    "    ax.grid(True)\n",
    "    ax.set_xticks(vetor_horizontes)\n",
    "    \n",
    "    # Inverte o eixo Y para que o rank 1 (melhor) fique no topo\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    # Ajusta os ticks do eixo Y para serem inteiros\n",
    "    y_ticks = np.arange(1, int(df_avg_rank['Rank_MAPE'].max()) + 2)\n",
    "    ax.set_yticks(y_ticks)\n",
    "    \n",
    "    ax.legend(title='Modelo')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783de987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_suite_completa_de_relatorios(output_file, vetor_horizontes):\n",
    "    \"\"\"Função principal que orquestra a geração de todos os relatórios.\"\"\"\n",
    "    print(\"\\n\\n\" + \"=\"*60); print(\"     INICIANDO GERAÇÃO DA SUÍTE COMPLETA DE RELATÓRIOS\"); print(\"=\"*60)\n",
    "    try:\n",
    "        df_results = pd.read_csv(output_file)\n",
    "        df_metricas_final = calcular_metricas_finais(df_results)\n",
    "        \n",
    "        # Chamada para os relatórios descritivos\n",
    "        plotar_evolucao_erro(df_metricas_final, vetor_horizontes)\n",
    "        plotar_evolucao_ranking_mape(df_metricas_final, vetor_horizontes)\n",
    "        \n",
    "        maior_horizonte = df_metricas_final['horizonte'].max()\n",
    "        df_foco_maior_h = df_metricas_final[df_metricas_final['horizonte'] == maior_horizonte]\n",
    "        display(Markdown(f\"### Análises Detalhadas para o Horizonte Mais Longo ({int(maior_horizonte)} passos)\"))\n",
    "        \n",
    "        exibir_desempenho_agregado(df_foco_maior_h)\n",
    "        exibir_desempenho_detalhado(df_foco_maior_h)\n",
    "        df_pivot_rank = exibir_tabela_ranking(df_foco_maior_h)\n",
    "        plotar_diferenca_percentual(df_foco_maior_h)\n",
    "        # --- CHAMADA PARA OS NOVOS RELATÓRIOS ---\n",
    "        exibir_ranking_mape_artigo(df_foco_maior_h)\n",
    "        plotar_pd_agregado(df_foco_maior_h)\n",
    "        \n",
    "        # Chamada para a nova análise estatística\n",
    "        p_values_nemenyi, avg_ranks = exibir_analise_estatistica_demsar(df_pivot_rank, maior_horizonte)\n",
    "        \n",
    "        # Chamada para o novo gráfico\n",
    "        plotar_diagrama_diferenca_critica(p_values_nemenyi, avg_ranks)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\nERRO: Arquivo '{output_file}' não encontrado.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro ao gerar os relatórios: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae016a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# SEÇÃO 8: EXECUÇÃO DA GERAÇÃO DE RELATÓRIOS\n",
    "# ================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f681fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "VETOR_DE_HORIZONTES = [10, 12, 15, 24] # Defina os horizontes que foram testados\n",
    "gerar_suite_completa_de_relatorios(output_file, VETOR_DE_HORIZONTES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybrid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
