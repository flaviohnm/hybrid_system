{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c96030f3be3e4a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T00:52:59.360703Z",
     "start_time": "2025-06-19T00:52:59.356446Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 1: IMPORTAÇÕES E SETUP GERAL\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9716172789275c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T00:52:59.414429Z",
     "start_time": "2025-06-19T00:52:59.376419Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "# Libs de Modelagem e Estatística\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.datasets import get_rdataset\n",
    "import pmdarima as pm\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS, MLP, LSTM, Autoformer\n",
    "from dieboldmariano import dm_test\n",
    "\n",
    "# Libs de Avaliação\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7acde5f0e5c4b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 2: FUNÇÕES AUXILIARES (SETUP E PROCESSAMENTO)\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ff04ae19676ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def definir_seed(seed_value=42):\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68444ac84157ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_dataset(serie, dataset_name):\n",
    "    dir_path = \"./datasets/bronze\"\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    file_path = os.path.join(dir_path, f\"{dataset_name.lower()}.csv\")\n",
    "    df = pd.DataFrame({\"date\": serie.index, \"value\": serie.values})\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"-> Cópia do dataset '{dataset_name}' salva em: {file_path}\")\n",
    "\n",
    "def carregar_serie(nome):\n",
    "    print(f\"Buscando dados de '{nome}' via statsmodels...\")\n",
    "    nome_base = nome.lower()\n",
    "\n",
    "    if nome_base == \"airpassengers\":\n",
    "        df = get_rdataset(\"AirPassengers\", package=\"datasets\").data\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1949-01-01\", periods=len(df), freq=\"MS\"),\n",
    "                          name=\"AirPassengers\")\n",
    "    elif nome_base == \"lynx\":\n",
    "        df = get_rdataset(\"lynx\", package=\"datasets\").data\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1821\", periods=len(df), freq=\"A\"), name=\"Lynx\")\n",
    "    elif nome_base == \"co2\":\n",
    "        df = get_rdataset(\"CO2\", package=\"datasets\").data\n",
    "        df = df.ffill()\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1958-03-29\", periods=len(df), freq=\"MS\"),\n",
    "                          name=\"CO2\")\n",
    "    elif nome_base == \"sunspots\":\n",
    "        df = get_rdataset(\"sunspots\", package=\"datasets\").data\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1749-01-01\", periods=len(df), freq=\"MS\"),\n",
    "                          name=\"Sunspots\")\n",
    "    elif nome_base == \"austres\":\n",
    "        df = get_rdataset(\"austres\", package=\"datasets\").data\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1971-03-01\", periods=len(df), freq=\"QS-MAR\"),\n",
    "                          name=\"AustralianResidents\")\n",
    "    elif nome_base == \"nottem\":\n",
    "        df = get_rdataset(\"nottem\", package=\"datasets\").data\n",
    "        serie = pd.Series(df['value'].values, index=pd.date_range(start=\"1920-01-01\", periods=len(df), freq=\"MS\"),\n",
    "                          name=\"Nottingham\")\n",
    "    else:\n",
    "        raise ValueError(f\"Lógica de download para a série '{nome}' não implementada.\")\n",
    "\n",
    "    salvar_dataset(serie, nome)\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a220cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_serie_temporal(serie, percentual_treino=0.7, percentual_validacao=0.15):\n",
    "    \"\"\"Divide a série em treino, validação e teste.\"\"\"\n",
    "    tamanho_total = len(serie)\n",
    "    ponto_corte_treino = int(tamanho_total * percentual_treino)\n",
    "    ponto_corte_validacao = int(tamanho_total * (percentual_treino + percentual_validacao))\n",
    "    treino = serie.iloc[:ponto_corte_treino]\n",
    "    validacao = serie.iloc[ponto_corte_treino:ponto_corte_validacao]\n",
    "    teste = serie.iloc[ponto_corte_validacao:]\n",
    "    return treino, validacao, teste\n",
    "\n",
    "def preparar_dados_para_neuralforecast(serie, nome_serie):\n",
    "    df = serie.reset_index()\n",
    "    df.columns = ['ds', 'y']\n",
    "    df['unique_id'] = nome_serie\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "767138d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 3: FUNÇÕES PARA CÁLCULO DE MÉTRICAS E MODELAGEM\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c38b31116385f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas(y_true, y_pred, y_train):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100 if np.all(y_true != 0) else np.inf\n",
    "    n = len(y_train)\n",
    "    d = np.sum(np.abs(y_train[1:] - y_train[:-1])) / (n - 1) if n > 1 else np.nan\n",
    "    mase = np.mean(np.abs(y_true - y_pred)) / d if d is not np.nan and d > 0 else np.inf\n",
    "    return {'RMSE': rmse, 'MAPE(%)': mape, 'MASE': mase}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cae6b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 4: PIPELINE AVANÇADO PARA O ARIMA\n",
    "# =========================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcc9d2b54e19eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_melhor_arima_auto(treino_log, freq):\n",
    "    \"\"\"Usa auto_arima para encontrar a melhor ordem ARIMA, incluindo sazonalidade.\"\"\"\n",
    "    print(\"Buscando melhor ordem ARIMA com auto_arima...\")\n",
    "    m = 1\n",
    "    if freq and freq.startswith('M'): m = 12\n",
    "    elif freq and freq.startswith('Q'): m = 4\n",
    "    \n",
    "    auto_arima_model = pm.auto_arima(\n",
    "        treino_log,\n",
    "        start_p=1, start_q=1,\n",
    "        max_p=3, max_q=3,\n",
    "        m=m,              # Frequência sazonal\n",
    "        seasonal=True,    # Habilita a busca por parâmetros sazonais (P,D,Q)\n",
    "        d=None,           # Deixa o auto_arima encontrar o melhor 'd'\n",
    "        D=None,           # Deixa o auto_arima encontrar o melhor 'D' sazonal\n",
    "        trace=False,      # Não imprime os passos da busca\n",
    "        error_action='ignore',\n",
    "        suppress_warnings=True,\n",
    "        stepwise=True     # Usa uma busca mais rápida e eficiente\n",
    "    )\n",
    "    print(f\"Melhor ordem encontrada: {auto_arima_model.order} Sazonal: {auto_arima_model.seasonal_order}\")\n",
    "    return auto_arima_model.order, auto_arima_model.seasonal_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "189a54af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 5: PIPELINE DE EXPERIMENTO COMPLETO E AVANÇADO\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f7c9b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executar_experimento(nome_da_serie):\n",
    "    \"\"\"Executa o pipeline completo com metodologia Treino-Validação-Teste para todos os 7 modelos.\"\"\"\n",
    "    try:\n",
    "        SEED = 42; definir_seed(SEED)\n",
    "        MAX_INPUT_SIZE = 24; MAX_STEPS_NEURAL = 100\n",
    "\n",
    "        serie_original = carregar_serie(nome_da_serie)\n",
    "        serie_log = np.log(serie_original)\n",
    "        \n",
    "        treino_log, validacao_log, teste_log = dividir_serie_temporal(serie_log)\n",
    "        treino_orig, validacao_orig, teste_orig = dividir_serie_temporal(serie_original)\n",
    "        \n",
    "        if len(teste_log) < 2 or len(validacao_log) < 2: return None, None\n",
    "        freq = serie_original.index.freqstr or pd.infer_freq(serie_original.index)\n",
    "        if freq is None: return None, None\n",
    "\n",
    "        resultados_validacao, resultados_teste = [], []\n",
    "        \n",
    "        horizonte_total = len(validacao_log) + len(teste_log)\n",
    "        input_size = min(2 * horizonte_total, MAX_INPUT_SIZE)\n",
    "\n",
    "        # --- 1. Encontrar a melhor ordem ARIMA e treinar o modelo base ---\n",
    "        # A chamada à função foi reintroduzida aqui\n",
    "        melhor_ordem, melhor_ordem_sazonal = encontrar_melhor_arima_auto(treino_log, freq)\n",
    "        modelo_arima, preds_log_valid_arima, preds_log_teste_arima = None, None, None\n",
    "        try:\n",
    "            print(f\"Processando: ARIMA\")\n",
    "            modelo_arima = ARIMA(treino_log.asfreq(freq), order=melhor_ordem, seasonal_order=melhor_ordem_sazonal).fit()\n",
    "            preds_log_futuro = modelo_arima.predict(start=validacao_log.index[0], end=teste_log.index[-1])\n",
    "            preds_log_valid_arima, preds_log_teste_arima = preds_log_futuro[:len(validacao_log)], preds_log_futuro[-len(teste_log):]\n",
    "            \n",
    "            metricas_val = calcular_metricas(validacao_orig.values, np.exp(preds_log_valid_arima), treino_orig.values); metricas_val['modelo'] = 'ARIMA'; resultados_validacao.append(metricas_val)\n",
    "            metricas_test = calcular_metricas(teste_orig.values, np.exp(preds_log_teste_arima), treino_orig.values); metricas_test['modelo'] = 'ARIMA'; resultados_teste.append(metricas_test)\n",
    "        except Exception as e:\n",
    "            print(f\"AVISO: Modelo ARIMA falhou: {e}\")\n",
    "\n",
    "        # --- 2. Modelos Neurais Puros ---\n",
    "        df_treino_log_nf = preparar_dados_para_neuralforecast(treino_log, nome_da_serie)\n",
    "        for nome_modelo, classe_modelo in {'N-BEATS': NBEATS, 'MLP': MLP, 'LSTM': LSTM, 'Autoformer': Autoformer}.items():\n",
    "            try:\n",
    "                print(f\"Processando: {nome_modelo} (MIMO)\")\n",
    "                modelo_neural = [classe_modelo(input_size=input_size, h=horizonte_total, max_steps=MAX_STEPS_NEURAL, scaler_type='standard', random_seed=SEED)]\n",
    "                nf = NeuralForecast(models=modelo_neural, freq=freq)\n",
    "                nf.fit(df=df_treino_log_nf, verbose=False)\n",
    "                preds_log_futuro_n = nf.predict()[nome_modelo].values\n",
    "                preds_log_valid_n, preds_log_teste_n = preds_log_futuro_n[:len(validacao_log)], preds_log_futuro_n[-len(teste_log):]\n",
    "                metricas_val = calcular_metricas(validacao_orig.values, np.exp(preds_log_valid_n), treino_orig.values); metricas_val['modelo'] = f'{nome_modelo} (MIMO)'; resultados_validacao.append(metricas_val)\n",
    "                metricas_test = calcular_metricas(teste_orig.values, np.exp(preds_log_teste_n), treino_orig.values); metricas_test['modelo'] = f'{nome_modelo} (MIMO)'; resultados_teste.append(metricas_test)\n",
    "            except Exception as e: print(f\"AVISO: Modelo {nome_modelo} falhou: {e}\")\n",
    "        \n",
    "        # --- 3. Modelos Híbridos ---\n",
    "        if modelo_arima is not None:\n",
    "            residuos_treino_log = modelo_arima.resid\n",
    "            df_residuos_nf = preparar_dados_para_neuralforecast(residuos_treino_log, \"residuos\")\n",
    "\n",
    "            # Híbrido ARIMA+N-BEATS(MIMO)\n",
    "            try:\n",
    "                print(\"Processando: Híbrido ARIMA+N-BEATS(MIMO)\")\n",
    "                modelo_residuos = [NBEATS(input_size=input_size, h=horizonte_total, max_steps=MAX_STEPS_NEURAL, scaler_type='standard', random_seed=SEED)]\n",
    "                nf_residuos = NeuralForecast(models=modelo_residuos, freq=freq)\n",
    "                nf_residuos.fit(df=df_residuos_nf, verbose=False)\n",
    "                preds_residuos_log = nf_residuos.predict()['NBEATS'].values\n",
    "                preds_hibrido_log_valid = preds_log_valid_arima.values + preds_residuos_log[:len(validacao_log)]\n",
    "                preds_hibrido_log_teste = preds_log_teste_arima.values + preds_residuos_log[-len(teste_log):]\n",
    "                metricas_val = calcular_metricas(validacao_orig.values, np.exp(preds_hibrido_log_valid), treino_orig.values); metricas_val['modelo'] = 'Híbrido (MIMO)'; resultados_validacao.append(metricas_val)\n",
    "                metricas_test = calcular_metricas(teste_orig.values, np.exp(preds_hibrido_log_teste), treino_orig.values); metricas_test['modelo'] = 'Híbrido (MIMO)'; resultados_teste.append(metricas_test)\n",
    "            except Exception as e: print(f\"AVISO: Modelo Híbrido (MIMO) falhou: {e}\")\n",
    "\n",
    "            # Híbrido HyS-MF (Direto)\n",
    "            try:\n",
    "                print(\"Processando: Híbrido HyS-MF (Direto) - Esta etapa é MUITO LENTA.\")\n",
    "                preds_residuos_direto_log = []\n",
    "                for h_step in tqdm(range(1, horizonte_total + 1), desc=\"Treinando modelos 'Direto'\"):\n",
    "                    residuos_target = residuos_treino_log.shift(-(h_step-1))\n",
    "                    df_direto_treino = preparar_dados_para_neuralforecast(residuos_target.dropna(), f\"residuos_h{h_step}\")\n",
    "                    modelo_h = [NBEATS(input_size=input_size, h=1, max_steps=MAX_STEPS_NEURAL, scaler_type='standard', random_seed=SEED)]\n",
    "                    nf_h = NeuralForecast(models=modelo_h, freq=freq)\n",
    "                    nf_h.fit(df=df_direto_treino, verbose=False)\n",
    "                    preds_residuos_log.append(nf_h.predict()['NBEATS'].values[0])\n",
    "\n",
    "                preds_hibrido_log_valid_direto = preds_log_valid_arima.values + preds_residuos_log[:len(validacao_log)]\n",
    "                preds_hibrido_log_teste_direto = preds_log_teste_arima.values + preds_residuos_log[-len(teste_log):]\n",
    "                metricas_val = calcular_metricas(validacao_orig.values, np.exp(preds_hibrido_log_valid_direto), treino_orig.values); metricas_val['modelo'] = 'HyS-MF (Direto)'; resultados_validacao.append(metricas_val)\n",
    "                metricas_test = calcular_metricas(teste_orig.values, np.exp(preds_hibrido_log_teste_direto), treino_orig.values); metricas_test['modelo'] = 'HyS-MF (Direto)'; resultados_teste.append(metricas_test)\n",
    "            except Exception as e: print(f\"AVISO: Modelo Híbrido (Direto) falhou: {e}\")\n",
    "\n",
    "        return pd.DataFrame(resultados_validacao), pd.DataFrame(resultados_teste)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO GERAL no processamento do dataset '{nome_da_serie}': {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a005504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 6: ORQUESTRADOR\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2ed971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando todos os datasets:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando dados de 'AirPassengers' via statsmodels...\n",
      "-> Cópia do dataset 'AirPassengers' salva em: ./datasets/bronze\\airpassengers.csv\n",
      "Buscando melhor ordem ARIMA com auto_arima...\n",
      "Melhor ordem encontrada: (2, 0, 0) Sazonal: (2, 1, 0, 12)\n",
      "Processando: ARIMA\n"
     ]
    }
   ],
   "source": [
    "LISTA_DE_DATASETS = ['AirPassengers'] \n",
    "resultados_validacao_geral, resultados_teste_geral = [], []\n",
    "\n",
    "for dataset in tqdm(LISTA_DE_DATASETS, desc=\"Processando todos os datasets\"):\n",
    "    df_validacao, df_teste = executar_experimento(dataset)\n",
    "    \n",
    "    if df_validacao is not None and not df_validacao.empty:\n",
    "        df_validacao['dataset'] = dataset\n",
    "        resultados_validacao_geral.append(df_validacao)\n",
    "    if df_teste is not None and not df_teste.empty:\n",
    "        df_teste['dataset'] = dataset\n",
    "        resultados_teste_geral.append(df_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df8e17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./datasets/silver\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "if resultados_validacao_geral:\n",
    "    pd.concat(resultados_validacao_geral).to_csv(os.path.join(output_dir, \"resultados_validacao.csv\"), index=False)\n",
    "    print(f\"\\nArquivo 'resultados_validacao.csv' salvo em: {output_dir}\")\n",
    "if resultados_teste_geral:\n",
    "    pd.concat(resultados_teste_geral).to_csv(os.path.join(output_dir, \"resultados_teste.csv\"), index=False)\n",
    "    print(f\"Arquivo 'resultados_teste.csv' salvo em: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e21be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SEÇÃO 7: GERAÇÃO DE RELATÓRIOS A PARTIR DOS ARQUIVOS SALVOS\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a1d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"     GERANDO RELATÓRIOS A PARTIR DOS DADOS SALVOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    # Carrega os resultados do arquivo de teste\n",
    "    df_teste_final = pd.read_csv(\"./datasets/silver/resultados_teste.csv\").rename(columns={'modelo': 'Modelo'})\n",
    "    \n",
    "    # --- Relatório 1: Desempenho Geral (Agrupado por Modelo) ---\n",
    "    print(\"\\n--- RELATÓRIO 1: DESEMPENHO GERAL (MÉDIA NOS DATASETS) ---\")\n",
    "    df_agrupado_por_modelo = df_teste_final.groupby('Modelo')[['RMSE', 'MAPE(%)', 'MASE']].mean()\n",
    "    display(df_agrupado_por_modelo.style.format('{:.3f}').highlight_min(axis=0, props='background-color: #4285F4; color: white;'))\n",
    "\n",
    "    # --- Relatório 2: Desempenho Detalhado por Dataset ---\n",
    "    print(\"\\n--- RELATÓRIO 2: DESEMPENHO DETALHADO POR DATASET (NO TESTE) ---\")\n",
    "    df_reporte_detalhado = df_teste_final.set_index(['dataset', 'Modelo'])\n",
    "    \n",
    "    def destacar_melhor_por_grupo(df):\n",
    "        df_style = pd.DataFrame('', index=df.index, columns=df.columns)\n",
    "        estilo_melhor = 'background-color: #4285F4; color: white; font-weight: bold;'\n",
    "        for metrica in ['RMSE', 'MAPE(%)', 'MASE']:\n",
    "            if metrica in df.columns:\n",
    "                idx_minimos = df.groupby('dataset')[metrica].idxmin()\n",
    "                df_style.loc[idx_minimos, metrica] = estilo_melhor\n",
    "        return df_style\n",
    "        \n",
    "    display(df_reporte_detalhado.style.format('{:.3f}').apply(destacar_melhor_por_grupo, axis=None))\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"\\nERRO: Arquivo 'resultados_teste.csv' não encontrado.\")\n",
    "    print(\"Por favor, execute a Seção 4 (Etapa de Execução e Salvamento) primeiro para gerar os resultados.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro ao gerar os relatórios: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybrid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
